[
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable.*",
    "options": [
      "Homoscedasticity",
      "Multicollinearity",
      "R-squared",
      "Spearman Correlation"
    ],
    "answer": 2,
    "explanation": "The definition describes **R-squared**.",
    "id": 89
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A general statement or default position that there is no relationship between two measured phenomena.*",
    "options": [
      "P-value",
      "Null Hypothesis",
      "Significance Level",
      "T-statistic"
    ],
    "answer": 1,
    "explanation": "The definition describes **Null Hypothesis**.",
    "id": 56
  },
  {
    "type": "tf",
    "question": "**Standard Error** is The standard deviation of the sampling distribution of a statistic.",
    "answer": true,
    "explanation": "**Standard Error (SEM)**: SD of the sampling distribution of the mean. `SEM = SD / sqrt(N)`. Decreases as N increases.",
    "id": 42,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "What is the best definition for **T-statistic**?",
    "options": [
      "The rejection of a true null hypothesis (false positive). (additional context) (a",
      "A ratio of the departure of the estimated value of a parameter from its hypothesized value...",
      "An inferential statistic used to assess the equality of variances for a variable calculated for two or more groups.",
      "The probability of rejecting the null hypothesis when it is true (alpha). (in statistics)"
    ],
    "answer": 1,
    "explanation": "**T-statistic** is defined as: A ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.",
    "id": 73
  },
  {
    "type": "tf",
    "question": "**Standard Deviation** is A measure of the amount of variation or dispersion of a set of values, calculated as the square root of variance.",
    "answer": true,
    "explanation": "True. Standard Deviation is indeed A measure of the amount of variation or dispersion of a set of values, calculated as the square root of variance.",
    "id": 30
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Shapiro-Wilk Test**?",
    "options": [
      "The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.",
      "The non-rejection of a false null hypothesis (false negative).",
      "A ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.",
      "A test of normality in frequentist statistics."
    ],
    "answer": 3,
    "explanation": "**Shapiro-Wilk Test** is defined as: A test of normality in frequentist statistics.",
    "id": 76
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Normal Distribution**?",
    "options": [
      "A continuous probability distribution that is symmetric about the mean, showing that data near the mean are...",
      "Two events are independent if the occurrence of one does not affect the probability of occurrence of the other.",
      "A function that describes the relative likelihood for a continuous random variable to take on a given value.",
      "The long-run average value of repetitions of the same experiment it represents. (additional context"
    ],
    "answer": 0,
    "explanation": "**Normal Distribution** is defined as: A continuous probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence.",
    "id": 10
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Central Limit Theorem**?",
    "options": [
      "The theory that the distribution of sample means approximates a normal distribution as the sample size becomes...",
      "A subset of a statistical population in which each member of the subset has an equal probability of being chosen.",
      "The standard deviation of the sampling distribution of a statistic. (additional context) (additional c",
      "A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand."
    ],
    "answer": 0,
    "explanation": "**Central Limit Theorem** is defined as: The theory that the distribution of sample means approximates a normal distribution as the sample size becomes larger.",
    "id": 37
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The assumption that the variance of the error term in a regression model is constant.*",
    "options": [
      "Homoscedasticity",
      "R-squared",
      "Spurious Correlation",
      "Pearson Correlation"
    ],
    "answer": 0,
    "explanation": "The definition describes **Homoscedasticity**.",
    "id": 98
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A theorem stating that the average of the results obtained from a large number of trials should be close to the expected value.*",
    "options": [
      "Stratified Sampling",
      "Sampling Bias",
      "Law of Large Numbers",
      "Convenience Sampling"
    ],
    "answer": 2,
    "explanation": "The definition describes **Law of Large Numbers**.",
    "id": 44
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Multicollinearity**?",
    "options": [
      "A phenomenon in which one predictor variable in a multiple regression model can be linearly...",
      "A non-parametric measure of rank correlation (statistical dependence between the rankings of two variables).",
      "The assumption that the variance of the error term in a regression model is constant.",
      "A measure of the linear correlation between two sets of data. (additional context) ("
    ],
    "answer": 0,
    "explanation": "**Multicollinearity** is defined as: A phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy.",
    "id": 94
  },
  {
    "type": "tf",
    "question": "**Multicollinearity** is The assumption that the variance of the error term in a regression model is constant.",
    "answer": false,
    "explanation": "False. That is the definition of **Homoscedasticity**. **Multicollinearity** is A phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy.",
    "id": 96
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The theory that the distribution of sample means approximates a normal distribution as the sample size becomes larger.*",
    "options": [
      "Sampling Distribution",
      "Convenience Sampling",
      "Central Limit Theorem",
      "Simple Random Sampling"
    ],
    "answer": 2,
    "explanation": "The definition describes **Central Limit Theorem**.",
    "id": 38
  },
  {
    "type": "tf",
    "question": "**Sampling Distribution** is A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand.",
    "answer": false,
    "explanation": "False. That is the definition of **Convenience Sampling**. **Sampling Distribution** is The probability distribution of a given random-sample-based statistic.",
    "id": 36
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*An inferential statistic used to assess the equality of variances for a variable calculated for two or more groups.*",
    "options": [
      "Power",
      "P-value",
      "T-statistic",
      "Levene's Test"
    ],
    "answer": 3,
    "explanation": "The definition describes **Levene's Test**.",
    "id": 80
  },
  {
    "type": "tf",
    "question": "**Type I Error** is The rejection of a true null hypothesis (false positive).",
    "answer": true,
    "explanation": "True. Type I Error is indeed The rejection of a true null hypothesis (false positive).",
    "id": 63
  },
  {
    "type": "tf",
    "question": "**Independence** is Two events are independent if the occurrence of one does not affect the probability of occurrence of the other.",
    "answer": true,
    "explanation": "True. Independence is indeed Two events are independent if the occurrence of one does not affect the probability of occurrence of the other.",
    "id": 24
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Probability Density Function (PDF)**?",
    "options": [
      "A continuous probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence.",
      "A variable whose values depend on outcomes of a random phenomenon.",
      "A function that gives the probability that a random variable X is less than or equal to x.",
      "A function that describes the relative likelihood for a continuous random variable to take on a given value."
    ],
    "answer": 3,
    "explanation": "**Probability Density Function (PDF)** is defined as: A function that describes the relative likelihood for a continuous random variable to take on a given value.",
    "id": 4
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A variable whose values depend on outcomes of a random phenomenon.*",
    "options": [
      "Random Variable",
      "Independence",
      "Sturges' Rule",
      "Standard Deviation"
    ],
    "answer": 0,
    "explanation": "The definition describes **Random Variable**.",
    "id": 14
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Standard Deviation**?",
    "options": [
      "Two events are independent if the occurrence of one does not affect the probability of occurrence of the other.",
      "A continuous probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence.",
      "A function that gives the probability that a random variable X is less than or equal to x.",
      "A measure of the amount of variation or dispersion of a set of values, calculated as the square root of variance."
    ],
    "answer": 3,
    "explanation": "**Standard Deviation** is defined as: A measure of the amount of variation or dispersion of a set of values, calculated as the square root of variance.",
    "id": 28
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Simple Random Sampling**?",
    "options": [
      "A theorem stating that the average of the results obtained from a large number of trials should be close to the expected value.",
      "A subset of a statistical population in which each member of the subset has an equal probability of being chosen.",
      "The theory that the distribution of sample means approximates a normal distribution as the sample size becomes larger.",
      "The probability distribution of a given random-sample-based statistic."
    ],
    "answer": 1,
    "explanation": "**Simple Random Sampling** is defined as: A subset of a statistical population in which each member of the subset has an equal probability of being chosen.",
    "id": 31
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A relationship in which two or more events or variables are associated but not causally related, due to either coincidence or the presence of a certain third, unseen factor.*",
    "options": [
      "Multicollinearity",
      "Spurious Correlation",
      "Spearman Correlation",
      "Pearson Correlation"
    ],
    "answer": 1,
    "explanation": "The definition describes **Spurious Correlation**.",
    "id": 92
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A measure of how much a set of numbers is spread out from their average value.*",
    "options": [
      "Cumulative Distribution Function (CDF)",
      "Expected Value",
      "Variance",
      "Independence"
    ],
    "answer": 2,
    "explanation": "The definition describes **Variance**.",
    "id": 20
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand.*",
    "options": [
      "Sampling Bias",
      "Law of Large Numbers",
      "Convenience Sampling",
      "Central Limit Theorem"
    ],
    "answer": 2,
    "explanation": "The definition describes **Convenience Sampling**.",
    "id": 50
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The probability of correctly rejecting the null hypothesis when it is false (1 - Beta).*",
    "options": [
      "Shapiro-Wilk Test",
      "Type II Error",
      "T-statistic",
      "Power"
    ],
    "answer": 3,
    "explanation": "The definition describes **Power**.",
    "id": 68
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Random Variable**?",
    "options": [
      "A variable whose values depend on outcomes of a random phenomenon.",
      "A method for determining the number of bins in a histogram, calculated as k = log2(n) + 1.",
      "A measure of how much a set of numbers is spread out from their average value.",
      "A continuous probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence."
    ],
    "answer": 0,
    "explanation": "**Random Variable** is defined as: A variable whose values depend on outcomes of a random phenomenon.",
    "id": 13
  },
  {
    "type": "tf",
    "question": "**Stratified Sampling** is A subset of a statistical population in which each member of the subset has an equal probability of being chosen.",
    "answer": false,
    "explanation": "False. That is the definition of **Simple Random Sampling**. **Stratified Sampling** is A method of sampling from a population which can be partitioned into subpopulations (strata).",
    "id": 48
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The long-run average value of repetitions of the same experiment it represents.*",
    "options": [
      "Expected Value",
      "Variance",
      "Standard Deviation",
      "Random Variable"
    ],
    "answer": 0,
    "explanation": "The definition describes **Expected Value**.",
    "id": 17
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A function that describes the relative likelihood for a continuous random variable to take on a given value.*",
    "options": [
      "Random Variable",
      "Standard Deviation",
      "Variance (in statistics)",
      "Probability Density Funct..."
    ],
    "answer": 3,
    "explanation": "The definition describes **Probability Density Function (PDF)**.",
    "id": 5
  },
  {
    "type": "tf",
    "question": "**Spearman Correlation** is A non-parametric measure of rank correlation (statistical dependence between the rankings of two variables).",
    "answer": true,
    "explanation": "True. Spearman Correlation is indeed A non-parametric measure of rank correlation (statistical dependence between the rankings of two variables).",
    "id": 87
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A measure of the amount of variation or dispersion of a set of values, calculated as the square root of variance.*",
    "options": [
      "Random Variable",
      "Cumulative Distribution Function (CDF)",
      "Standard Deviation",
      "Variance"
    ],
    "answer": 2,
    "explanation": "The definition describes **Standard Deviation**.",
    "id": 29
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A discrete probability distribution of the number of successes in a sequence of n independent experiments.*",
    "options": [
      "Normal Distribution",
      "Binomial Distribution",
      "Cumulative Distribution Function (CDF)",
      "Sturges' Rule"
    ],
    "answer": 1,
    "explanation": "The definition describes **Binomial Distribution**.",
    "id": 2
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Spearman Correlation**?",
    "options": [
      "A relationship in which two or more events or variables are associated but not causally related, due to either coincidence or the presence of a certain third, unseen factor.",
      "A measure of the linear correlation between two sets of data.",
      "A statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable.",
      "A non-parametric measure of rank correlation (statistical dependence between the rankings of two variables)."
    ],
    "answer": 3,
    "explanation": "**Spearman Correlation** is defined as: A non-parametric measure of rank correlation (statistical dependence between the rankings of two variables).",
    "id": 85
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Sampling Distribution**?",
    "options": [
      "A subset of a statistical population in which each member of the subset has an equal probability of being chosen.",
      "The theory that the distribution of sample means approximates a normal distribution as the sample size becomes larger.",
      "A bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others.",
      "The probability distribution of a given random-sample-based statistic."
    ],
    "answer": 3,
    "explanation": "**Sampling Distribution** is defined as: The probability distribution of a given random-sample-based statistic.",
    "id": 34
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A method of sampling from a population which can be partitioned into subpopulations (strata).*",
    "options": [
      "Sampling Bias",
      "Stratified Sampling",
      "Sampling Distribution",
      "Standard Error"
    ],
    "answer": 1,
    "explanation": "The definition describes **Stratified Sampling**.",
    "id": 47
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Spurious Correlation**?",
    "options": [
      "A non-parametric measure of rank correlation (statistical dependence between the rankings of two variables). (in statistics)",
      "The assumption that the variance of the error term in a regression model is constant. (additional context) (addition",
      "A phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy.",
      "A relationship in which two or more events or variables are associated but not causally related,"
    ],
    "answer": 3,
    "explanation": "**Spurious Correlation** is defined as: A relationship in which two or more events or variables are associated but not causally related, due to either coincidence or the presence of a certain third, unseen factor.",
    "id": 91
  },
  {
    "type": "tf",
    "question": "**Homoscedasticity** is A statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable.",
    "answer": false,
    "explanation": "False. That is the definition of **R-squared**. **Homoscedasticity** is The assumption that the variance of the error term in a regression model is constant.",
    "id": 99
  },
  {
    "type": "tf",
    "question": "**Pearson Correlation** is A measure of the linear correlation between two sets of data.",
    "answer": true,
    "explanation": "True. Pearson Correlation is indeed A measure of the linear correlation between two sets of data.",
    "id": 84
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The standard deviation of the sampling distribution of a statistic.*",
    "options": [
      "Law of Large Numbers",
      "Simple Random Sampling",
      "Sampling Distribution",
      "Standard Error"
    ],
    "answer": 3,
    "explanation": "The definition describes **Standard Error**.",
    "id": 41
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The rejection of a true null hypothesis (false positive).*",
    "options": [
      "Type I Error",
      "Shapiro-Wilk Test",
      "P-value",
      "Type II Error"
    ],
    "answer": 0,
    "explanation": "The definition describes **Type I Error**.",
    "id": 62
  },
  {
    "type": "tf",
    "question": "**R-squared** is A statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable.",
    "answer": true,
    "explanation": "True. R-squared is indeed A statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable.",
    "id": 90
  },
  {
    "type": "tf",
    "question": "**Random Variable** is A variable whose values depend on outcomes of a random phenomenon.",
    "answer": true,
    "explanation": "True. Random Variable is indeed A variable whose values depend on outcomes of a random phenomenon.",
    "id": 15
  },
  {
    "type": "tf",
    "question": "**Power** is A ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.",
    "answer": false,
    "explanation": "False. That is the definition of **T-statistic**. **Power** is The probability of correctly rejecting the null hypothesis when it is false (1 - Beta).",
    "id": 69
  },
  {
    "type": "tf",
    "question": "**Law of Large Numbers** is A method of sampling from a population which can be partitioned into subpopulations (strata).",
    "answer": false,
    "explanation": "False. That is the definition of **Stratified Sampling**. **Law of Large Numbers** is A theorem stating that the average of the results obtained from a large number of trials should be close to the expected value.",
    "id": 45
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Power**?",
    "options": [
      "A ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.",
      "The probability of rejecting the null hypothesis when it is true (alpha).",
      "The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.",
      "The probability of correctly rejecting the null hypothesis when it is false (1 - Beta)."
    ],
    "answer": 3,
    "explanation": "**Power** is defined as: The probability of correctly rejecting the null hypothesis when it is false (1 - Beta).",
    "id": 67
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Cumulative Distribution Function (CDF)**?",
    "options": [
      "A variable whose values depend on outcomes of a random phenomenon.",
      "Two events are independent if the occurrence of one does not affect the probability of occurrence of the other.",
      "A function that gives the probability that a random variable X is less than or equal to x.",
      "A function that describes the relative likelihood for a continuous random variable to take on a given value."
    ],
    "answer": 2,
    "explanation": "**Cumulative Distribution Function (CDF)** is defined as: A function that gives the probability that a random variable X is less than or equal to x.",
    "id": 7
  },
  {
    "type": "tf",
    "question": "**T-statistic** is A ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.",
    "answer": true,
    "explanation": "True. T-statistic is indeed A ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.",
    "id": 75
  },
  {
    "type": "tf",
    "question": "**Spurious Correlation** is The assumption that the variance of the error term in a regression model is constant.",
    "answer": false,
    "explanation": "False. That is the definition of **Homoscedasticity**. **Spurious Correlation** is A relationship in which two or more events or variables are associated but not causally related, due to either coincidence or the presence of a certain third, unseen factor.",
    "id": 93
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Stratified Sampling**?",
    "options": [
      "The standard deviation of the sampling distribution of a statistic.",
      "A method of sampling from a population which can be partitioned into subpopulations (strata).",
      "A bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others.",
      "A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand."
    ],
    "answer": 1,
    "explanation": "**Stratified Sampling** is defined as: A method of sampling from a population which can be partitioned into subpopulations (strata).",
    "id": 46
  },
  {
    "type": "tf",
    "question": "**Sampling Bias** is A method of sampling from a population which can be partitioned into subpopulations (strata).",
    "answer": false,
    "explanation": "False. That is the definition of **Stratified Sampling**. **Sampling Bias** is A bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others.",
    "id": 54
  },
  {
    "type": "tf",
    "question": "**Simple Random Sampling** is A subset of a statistical population in which each member of the subset has an equal probability of being chosen.",
    "answer": true,
    "explanation": "True. Simple Random Sampling is indeed A subset of a statistical population in which each member of the subset has an equal probability of being chosen.",
    "id": 33
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Null Hypothesis**?",
    "options": [
      "The non-rejection of a false null hypothesis (false negative). (in statistics)",
      "The rejection of a true null hypothesis (false positive). (in statistics)",
      "The probability of correctly rejecting the null hypothesis when it is false (1 - Beta).",
      "A general statement or default position that there is no relationship between..."
    ],
    "answer": 3,
    "explanation": "**Null Hypothesis** is defined as: A general statement or default position that there is no relationship between two measured phenomena.",
    "id": 55
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Homoscedasticity**?",
    "options": [
      "The assumption that the variance of the error term in a regression model is constant.",
      "A measure of the linear correlation between two sets of data.",
      "A phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy.",
      "A relationship in which two or more events or variables are associated but not causally related, due to either coincidence or the presence of a certain third, unseen factor."
    ],
    "answer": 0,
    "explanation": "**Homoscedasticity** is defined as: The assumption that the variance of the error term in a regression model is constant.",
    "id": 97
  },
  {
    "type": "tf",
    "question": "**Null Hypothesis** is The non-rejection of a false null hypothesis (false negative).",
    "answer": false,
    "explanation": "False. That is the definition of **Type II Error**. **Null Hypothesis** is A general statement or default position that there is no relationship between two measured phenomena.",
    "id": 57
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A continuous probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence.*",
    "options": [
      "Normal Distribution",
      "Probability Density Function (PDF)",
      "Variance",
      "Sturges' Rule"
    ],
    "answer": 0,
    "explanation": "The definition describes **Normal Distribution**.",
    "id": 11
  },
  {
    "type": "tf",
    "question": "**Levene's Test** is An inferential statistic used to assess the equality of variances for a variable calculated for two or more groups.",
    "answer": true,
    "explanation": "True. Levene's Test is indeed An inferential statistic used to assess the equality of variances for a variable calculated for two or more groups.",
    "id": 81
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.*",
    "options": [
      "T-statistic",
      "Power",
      "Null Hypothesis",
      "Levene's Test"
    ],
    "answer": 0,
    "explanation": "The definition describes **T-statistic**.",
    "id": 74
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The probability of rejecting the null hypothesis when it is true (alpha).*",
    "options": [
      "Power",
      "Type II Error",
      "Significance Level",
      "Type I Error"
    ],
    "answer": 2,
    "explanation": "The definition describes **Significance Level**.",
    "id": 71
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*Two events are independent if the occurrence of one does not affect the probability of occurrence of the other.*",
    "options": [
      "Normal Distribution",
      "Cumulative Distribution Function (CDF)",
      "Independence",
      "Sturges' Rule"
    ],
    "answer": 2,
    "explanation": "The definition describes **Independence**.",
    "id": 23
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The probability distribution of a given random-sample-based statistic.*",
    "options": [
      "Sampling Distribution",
      "Stratified Sampling",
      "Central Limit Theorem",
      "Sampling Bias"
    ],
    "answer": 0,
    "explanation": "The definition describes **Sampling Distribution**.",
    "id": 35
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A measure of the linear correlation between two sets of data.*",
    "options": [
      "Spurious Correlation",
      "R-squared",
      "Pearson Correlation",
      "Spearman Correlation"
    ],
    "answer": 2,
    "explanation": "The definition describes **Pearson Correlation**.",
    "id": 83
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A non-parametric measure of rank correlation (statistical dependence between the rankings of two variables).*",
    "options": [
      "Spearman Correlation",
      "Multicollinearity",
      "Homoscedasticity",
      "Spurious Correlation"
    ],
    "answer": 0,
    "explanation": "The definition describes **Spearman Correlation**.",
    "id": 86
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Convenience Sampling**?",
    "options": [
      "A subset of a statistical population in which each member of the subset has an equal probability of being chosen.",
      "The theory that the distribution of sample means approximates a normal distribution as the sample size becomes larger.",
      "A bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others.",
      "A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand."
    ],
    "answer": 3,
    "explanation": "**Convenience Sampling** is defined as: A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand.",
    "id": 49
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others.*",
    "options": [
      "Convenience Sampling",
      "Central Limit Theorem",
      "Sampling Bias",
      "Standard Error"
    ],
    "answer": 2,
    "explanation": "The definition describes **Sampling Bias**.",
    "id": 53
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A test of normality in frequentist statistics.*",
    "options": [
      "Shapiro-Wilk Test",
      "Type I Error",
      "P-value",
      "T-statistic"
    ],
    "answer": 0,
    "explanation": "The definition describes **Shapiro-Wilk Test**.",
    "id": 77
  },
  {
    "type": "mc",
    "question": "What is the best definition for **R-squared**?",
    "options": [
      "A statistical measure that represents the proportion of the variance for a dependent variable that's explained...",
      "A measure of the linear correlation between two sets of data. (additional context) (additional conte",
      "A phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy.",
      "The assumption that the variance of the error term in a regression model is constant. (in statistics)"
    ],
    "answer": 0,
    "explanation": "**R-squared** is defined as: A statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable.",
    "id": 88
  },
  {
    "type": "tf",
    "question": "**Cumulative Distribution Function (CDF)** is A function that gives the probability that a random variable X is less than or equal to x.",
    "answer": true,
    "explanation": "True. Cumulative Distribution Function (CDF) is indeed A function that gives the probability that a random variable X is less than or equal to x.",
    "id": 9
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.*",
    "options": [
      "Type I Error",
      "Significance Level",
      "P-value",
      "Levene's Test"
    ],
    "answer": 2,
    "explanation": "The definition describes **P-value**.",
    "id": 59
  },
  {
    "type": "tf",
    "question": "**Convenience Sampling** is A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand.",
    "answer": true,
    "explanation": "True. Convenience Sampling is indeed A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand.",
    "id": 51
  },
  {
    "type": "mc",
    "question": "What is the best definition for **P-value**?",
    "options": [
      "A test of normality in frequentist statistics. (in statistics)",
      "The rejection of a true null hypothesis (false positive). approach",
      "The probability of rejecting the null hypothesis when it is true (alpha).",
      "The probability of obtaining test results at least as extreme as the..."
    ],
    "answer": 3,
    "explanation": "**P-value** is defined as: The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.",
    "id": 58
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Law of Large Numbers**?",
    "options": [
      "A theorem stating that the average of the results obtained from a large number of trials...",
      "The probability distribution of a given random-sample-based statistic. (in statistics)",
      "The standard deviation of the sampling distribution of a statistic. in data analysis",
      "A subset of a statistical population in which each member of the subset has an equal probability of being chosen."
    ],
    "answer": 0,
    "explanation": "**Law of Large Numbers** is defined as: A theorem stating that the average of the results obtained from a large number of trials should be close to the expected value.",
    "id": 43
  },
  {
    "type": "tf",
    "question": "**Normal Distribution** is A function that gives the probability that a random variable X is less than or equal to x.",
    "answer": false,
    "explanation": "False. That is the definition of **Cumulative Distribution Function (CDF)**. **Normal Distribution** is A continuous probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence.",
    "id": 12
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Sampling Bias**?",
    "options": [
      "The probability distribution of a given random-sample-based statistic. (additional context) (add",
      "A bias in which a sample is collected in such a way that some members of the intended population have a...",
      "A method of sampling from a population which can be partitioned into subpopulations (strata). methodology",
      "A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand."
    ],
    "answer": 1,
    "explanation": "**Sampling Bias** is defined as: A bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others.",
    "id": 52
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Independence**?",
    "options": [
      "A discrete probability distribution of the number of successes in a sequence of n independent experiments.",
      "The long-run average value of repetitions of the same experiment it represents.",
      "A continuous probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence.",
      "Two events are independent if the occurrence of one does not affect the probability of occurrence of the other."
    ],
    "answer": 3,
    "explanation": "**Independence** is defined as: Two events are independent if the occurrence of one does not affect the probability of occurrence of the other.",
    "id": 22
  },
  {
    "type": "tf",
    "question": "**Sturges' Rule** is A function that describes the relative likelihood for a continuous random variable to take on a given value.",
    "answer": false,
    "explanation": "False. That is the definition of **Probability Density Function (PDF)**. **Sturges' Rule** is A method for determining the number of bins in a histogram, calculated as k = log2(n) + 1.",
    "id": 27
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Levene's Test**?",
    "options": [
      "A test of normality in frequentist statistics. (additional context) (additional context) (a",
      "The probability of correctly rejecting the null hypothesis when it is false (1 - Beta). methodology",
      "The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.",
      "An inferential statistic used to assess the equality of variances for a variable calculated for two or"
    ],
    "answer": 3,
    "explanation": "**Levene's Test** is defined as: An inferential statistic used to assess the equality of variances for a variable calculated for two or more groups.",
    "id": 79
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Significance Level**?",
    "options": [
      "An inferential statistic used to assess the equality of variances for a variable calculated for two or more groups.",
      "The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.",
      "A ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error.",
      "The probability of rejecting the null hypothesis when it is true (alpha)."
    ],
    "answer": 3,
    "explanation": "**Significance Level** is defined as: The probability of rejecting the null hypothesis when it is true (alpha).",
    "id": 70
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Variance**?",
    "options": [
      "A function that describes the relative likelihood for a continuous random variable to take on a given value.",
      "Two events are independent if the occurrence of one does not affect the probability of occurrence of the other.",
      "A discrete probability distribution of the number of successes in a sequence of n independent experiments.",
      "A measure of how much a set of numbers is spread out from their average value."
    ],
    "answer": 3,
    "explanation": "**Variance** is defined as: A measure of how much a set of numbers is spread out from their average value.",
    "id": 19
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Expected Value**?",
    "options": [
      "A function that gives the probability that a random variable X is less than or equal to x.",
      "A measure of how much a set of numbers is spread out from their average value.",
      "The long-run average value of repetitions of the same experiment it represents.",
      "A function that describes the relative likelihood for a continuous random variable to take on a given value."
    ],
    "answer": 2,
    "explanation": "**Expected Value** is defined as: The long-run average value of repetitions of the same experiment it represents.",
    "id": 16
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Sturges' Rule**?",
    "options": [
      "A method for determining the number of bins in a histogram, calculated as k = log2(n) + 1.",
      "A function that describes the relative likelihood for a continuous random variable to take on a given value.",
      "A function that gives the probability that a random variable X is less than or equal to x.",
      "A variable whose values depend on outcomes of a random phenomenon."
    ],
    "answer": 0,
    "explanation": "**Sturges' Rule** is defined as: A method for determining the number of bins in a histogram, calculated as k = log2(n) + 1.",
    "id": 25
  },
  {
    "type": "tf",
    "question": "**Probability Density Function (PDF)** is A function that describes the relative likelihood for a continuous random variable to take on a given value.",
    "answer": true,
    "explanation": "True. Probability Density Function (PDF) is indeed A function that describes the relative likelihood for a continuous random variable to take on a given value.",
    "id": 6
  },
  {
    "type": "tf",
    "question": "**Type II Error** is An inferential statistic used to assess the equality of variances for a variable calculated for two or more groups.",
    "answer": false,
    "explanation": "False. That is the definition of **Levene's Test**. **Type II Error** is The non-rejection of a false null hypothesis (false negative).",
    "id": 66
  },
  {
    "type": "tf",
    "question": "**Shapiro-Wilk Test** is A test of normality in frequentist statistics.",
    "answer": true,
    "explanation": "True. Shapiro-Wilk Test is indeed A test of normality in frequentist statistics.",
    "id": 78
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy.*",
    "options": [
      "Pearson Correlation",
      "Homoscedasticity",
      "Multicollinearity",
      "R-squared"
    ],
    "answer": 2,
    "explanation": "The definition describes **Multicollinearity**.",
    "id": 95
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A function that gives the probability that a random variable X is less than or equal to x.*",
    "options": [
      "Binomial Distribution",
      "Probability Density Function (PDF)",
      "Cumulative Distribution Function (CDF)",
      "Normal Distribution"
    ],
    "answer": 2,
    "explanation": "The definition describes **Cumulative Distribution Function (CDF)**.",
    "id": 8
  },
  {
    "type": "tf",
    "question": "**Expected Value** is The long-run average value of repetitions of the same experiment it represents.",
    "answer": true,
    "explanation": "True. Expected Value is indeed The long-run average value of repetitions of the same experiment it represents.",
    "id": 18
  },
  {
    "type": "tf",
    "question": "**Significance Level** is The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.",
    "answer": false,
    "explanation": "False. That is the definition of **P-value**. **Significance Level** is The probability of rejecting the null hypothesis when it is true (alpha).",
    "id": 72
  },
  {
    "type": "tf",
    "question": "**P-value** is The rejection of a true null hypothesis (false positive).",
    "answer": false,
    "explanation": "False. That is the definition of **Type I Error**. **P-value** is The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.",
    "id": 60
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Binomial Distribution**?",
    "options": [
      "A variable whose values depend on outcomes of a random phenomenon.",
      "A measure of the amount of variation or dispersion of a set of values, calculated as the square root of variance.",
      "A discrete probability distribution of the number of successes in a sequence of n independent experiments.",
      "Two events are independent if the occurrence of one does not affect the probability of occurrence of the other."
    ],
    "answer": 2,
    "explanation": "**Binomial Distribution** is defined as: A discrete probability distribution of the number of successes in a sequence of n independent experiments.",
    "id": 1
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Standard Error**?",
    "options": [
      "The standard deviation of the sampling distribution of a statistic.",
      "A type of non-probability sampling that involves the sample being drawn from that part of the population that is close to hand.",
      "A method of sampling from a population which can be partitioned into subpopulations (strata).",
      "A bias in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling probability than others."
    ],
    "answer": 0,
    "explanation": "**Standard Error** is defined as: The standard deviation of the sampling distribution of a statistic.",
    "id": 40
  },
  {
    "type": "tf",
    "question": "**Variance** is A discrete probability distribution of the number of successes in a sequence of n independent experiments.",
    "answer": false,
    "explanation": "False. That is the definition of **Binomial Distribution**. **Variance** is A measure of how much a set of numbers is spread out from their average value.",
    "id": 21
  },
  {
    "type": "tf",
    "question": "**Central Limit Theorem** is The theory that the distribution of sample means approximates a normal distribution as the sample size becomes larger.",
    "answer": true,
    "explanation": "True. Central Limit Theorem is indeed The theory that the distribution of sample means approximates a normal distribution as the sample size becomes larger.",
    "id": 39
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Pearson Correlation**?",
    "options": [
      "The assumption that the variance of the error term in a regression model is constant.",
      "A statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable.",
      "A measure of the linear correlation between two sets of data.",
      "A relationship in which two or more events or variables are associated but not causally related, due to either coincidence or the presence of a certain third, unseen factor."
    ],
    "answer": 2,
    "explanation": "**Pearson Correlation** is defined as: A measure of the linear correlation between two sets of data.",
    "id": 82
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Type I Error**?",
    "options": [
      "The probability of correctly rejecting the null hypothesis when it is false (1 - Beta).",
      "The probability of rejecting the null hypothesis when it is true (alpha).",
      "The non-rejection of a false null hypothesis (false negative).",
      "The rejection of a true null hypothesis (false positive)."
    ],
    "answer": 3,
    "explanation": "**Type I Error** is defined as: The rejection of a true null hypothesis (false positive).",
    "id": 61
  },
  {
    "type": "mc",
    "question": "What is the best definition for **Type II Error**?",
    "options": [
      "The probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct.",
      "A test of normality in frequentist statistics.",
      "The non-rejection of a false null hypothesis (false negative).",
      "The probability of rejecting the null hypothesis when it is true (alpha)."
    ],
    "answer": 2,
    "explanation": "**Type II Error** is defined as: The non-rejection of a false null hypothesis (false negative).",
    "id": 64
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A subset of a statistical population in which each member of the subset has an equal probability of being chosen.*",
    "options": [
      "Convenience Sampling",
      "Central Limit Theorem",
      "Simple Random Sampling",
      "Stratified Sampling"
    ],
    "answer": 2,
    "explanation": "The definition describes **Simple Random Sampling**.",
    "id": 32
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*A method for determining the number of bins in a histogram, calculated as k = log2(n) + 1.*",
    "options": [
      "Binomial Distribution",
      "Probability Density Function (PDF)",
      "Sturges' Rule",
      "Variance"
    ],
    "answer": 2,
    "explanation": "The definition describes **Sturges' Rule**.",
    "id": 26
  },
  {
    "type": "tf",
    "question": "**Binomial Distribution** is A method for determining the number of bins in a histogram, calculated as k = log2(n) + 1.",
    "answer": false,
    "explanation": "False. That is the definition of **Sturges' Rule**. **Binomial Distribution** is A discrete probability distribution of the number of successes in a sequence of n independent experiments.",
    "id": 3
  },
  {
    "type": "mc",
    "question": "Which concept corresponds to the following definition?\n\n*The non-rejection of a false null hypothesis (false negative).*",
    "options": [
      "Type I Error",
      "Type II Error",
      "Shapiro-Wilk Test",
      "Null Hypothesis"
    ],
    "answer": 1,
    "explanation": "The definition describes **Type II Error**.",
    "id": 65
  },
  {
    "type": "mc",
    "question": "Which distribution describes the probability of a specific number of \"successes\" in a fixed number of independent binary trials?",
    "options": [
      "Normal Distribution",
      "T-Distribution",
      "Binomial Distribution",
      "Chi-Square Distribution"
    ],
    "answer": 2,
    "explanation": "**Binomial Distribution** is defined as: Describes the probability of k successes in n binary trials. Use `dbinom(k, n, p)` for exact probability and `pbinom(k, n, p)` for cumulative.",
    "id": 100,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "In R, which function prefix is used to generate random numbers from a specific distribution?",
    "options": [
      "`d` (e.g., `dnorm`)",
      "`p` (e.g., `pnorm`)",
      "`q` (e.g., `qnorm`)",
      "`r` (e.g., `rnorm`)"
    ],
    "answer": 3,
    "explanation": "`r` (random), `d` (density/probability), `p` (cumulative), `q` (quantile). e.g., `rnorm` generates random data.",
    "id": 101,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "The area under the curve of a probability density function must always sum to:",
    "options": [
      "0",
      "0.5",
      "1",
      "100"
    ],
    "answer": 2,
    "explanation": "**PDF Area**: The total area under a Probability Density Function curve is always 1.",
    "id": 102,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "What does the function `pnorm(1.96)` return in R?",
    "options": [
      "The probability density at Z = 1.96",
      "The cumulative probability (area to the left) of Z = 1.96",
      "A random number from a normal distribution",
      "The Z-score corresponding to the 1.96th percentile"
    ],
    "answer": 1,
    "explanation": "**pnorm(z)**: Returns the cumulative probability (area to the left) for a Z-score. `pnorm(1.96)` is approx 0.975.",
    "id": 103,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "Which of the following describes a Normal Distribution?",
    "options": [
      "It is discrete and bimodal. methodology",
      "It is continuous, symmetric, and \"bell-shap...",
      "It is always skewed to the right.",
      "It describes binary outcomes only."
    ],
    "answer": 1,
    "explanation": "**Normal Distribution**: Symmetric, bell-shaped continuous distribution defined by mean and SD. approx 68% data within 1 SD, 95% within 2 SD.",
    "id": 104,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "If you want to calculate the probability of getting exactly 4 heads in 10 coin flips, which R function should you use?",
    "options": [
      "`rbinom(4, 10, 0.5)`",
      "`dbinom(4, 10, 0.5)`",
      "`pbinom(4, 10, 0.5)`",
      "`qbinom(4, 10, 0.5)`"
    ],
    "answer": 1,
    "explanation": "**cor() function**: Calculates correlation in R.",
    "id": 105,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "In a standard normal distribution (Z-distribution), what are the mean ($\\mu$) and standard deviation ($\\sigma$)?",
    "options": [
      "$\\mu = 1, \\sigma = 0$",
      "$\\mu = 100, \\sigma = 15$",
      "$\\mu = 0, \\sigma = 1$",
      "$\\mu = 0, \\sigma = 0$"
    ],
    "answer": 2,
    "explanation": "**Normal Distribution**: Symmetric, bell-shaped continuous distribution defined by mean and SD. approx 68% data within 1 SD, 95% within 2 SD.",
    "id": 106,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "Which distribution is typically used when testing hypotheses about categorical data or model comparison?",
    "options": [
      "T-distribution",
      "F-distribution",
      "Binomial distribution",
      "Chi-square distribution"
    ],
    "answer": 3,
    "explanation": "**F-distribution**: Used in ANOVA and regression to compare variances or models. Ratio of two chi-squares.",
    "id": 107,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "Skewness refers to:",
    "options": [
      "The \"peakedness\" or flatness of a distribution.",
      "The measure of asymmetry of a distribution.",
      "The spread of the data around the mean.",
      "The number of modes in a distribution."
    ],
    "answer": 1,
    "explanation": "**Skewness**: Measure of asymmetry. Positive skew = tail to right. Negative skew = tail to left.",
    "id": 108,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "What does the `set.seed(123)` function do in R?",
    "options": [
      "It randomizes the order of your dataframe.",
      "It ensures that random number generation is...",
      "It installs the \"seed\" package. methodology",
      "It calculates the standard error. methodology"
    ],
    "answer": 1,
    "explanation": "**set.seed()**: Initializes random number generator for reproducibility. Same seed = same random numbers.",
    "id": 109,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "The probability of an event occurring ranges between:",
    "options": [
      "-1 and 1",
      "0 and 1",
      "0 and 100",
      "$-\\infty$ and $+\\infty$"
    ],
    "answer": 1,
    "explanation": "**Probability Range**: Probabilities are always between 0 and 1.",
    "id": 110,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "If a distribution has \"heavy tails\" (high kurtosis), it means:",
    "options": [
      "There are more frequent extreme values (outlier...",
      "The distribution is very flat. methodology",
      "The distribution is skewed to the left.",
      "The mean is smaller than the median."
    ],
    "answer": 0,
    "explanation": "**Kurtosis**: Measure of tailedness. High kurtosis (leptokurtic) = heavy tails, potential outliers.",
    "id": 111,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "Which function would you use to find the Z-score that corresponds to the top 5% of the normal distribution?",
    "options": [
      "`dnorm(0.05)`",
      "`pnorm(0.95)`",
      "`qnorm(0.95)`",
      "`rnorm(0.95)`"
    ],
    "answer": 2,
    "explanation": "**Normal Distribution**: Symmetric, bell-shaped continuous distribution defined by mean and SD. approx 68% data within 1 SD, 95% within 2 SD.",
    "id": 112,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "In the context of probability, an \"elementary event\" refers to:",
    "options": [
      "An event that can be broken down into smaller parts.",
      "The entire sample space. (in statistics)",
      "A single outcome of an experiment (e.g.,",
      "The probability of zero. (in statistics)"
    ],
    "answer": 2,
    "explanation": "**Elementary Event**: A single outcome of an experiment (e.g., rolling a 5).",
    "id": 113,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "The F-distribution is most commonly associated with which statistical test?",
    "options": [
      "T-test (in statistics)",
      "Correlation methodology",
      "ANOVA (Analysis of Var...",
      "Binomial test approach"
    ],
    "answer": 2,
    "explanation": "**F-distribution**: Used in ANOVA and regression to compare variances or models. Ratio of two chi-squares.",
    "id": 114,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "If you flip a fair coin 100 times, the expected number of heads is 50. If you observe 48 heads, the difference is likely due to:",
    "options": [
      "Systemic bias",
      "Sampling error / Chance",
      "A Type I error",
      "Calculation error"
    ],
    "answer": 1,
    "explanation": "**Expected Value vs Observation**: Differences between observed data and expected value are due to sampling error (chance), assuming H0 is true.",
    "id": 115,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "Which of the following is a *continuous* probability distribution?",
    "options": [
      "Binomial distribution",
      "Normal distribution",
      "Poisson distribution",
      "Bernoulli distribution"
    ],
    "answer": 1,
    "explanation": "**Normal Distribution** is defined as: Symmetric, bell-shaped continuous distribution defined by mean and SD. approx 68% data within 1 SD, 95% within 2 SD.",
    "id": 116,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "If you increase the standard deviation of a normal distribution, the curve becomes:",
    "options": [
      "Taller and narrower",
      "Flatter and wider",
      "Skewed to the right",
      "Bimodal"
    ],
    "answer": 1,
    "explanation": "**Normal Distribution**: Symmetric, bell-shaped continuous distribution defined by mean and SD. approx 68% data within 1 SD, 95% within 2 SD.",
    "id": 117,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "What is the `size` argument in the `dbinom(x, size, prob)` function?",
    "options": [
      "The number of successes you are interested in.",
      "The probability of success.",
      "The total number of trials.",
      "The sample size of the population."
    ],
    "answer": 2,
    "explanation": "**dbinom size argument**: `size` refers to the number of trials (n), not the sample size of the study.",
    "id": 118,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "Why do we use probability theory in statistics?",
    "options": [
      "To prove that our data is correct.",
      "To calculate the exact population parameters.",
      "To estimate how likely our sample data is,",
      "To avoid doing math. (in statistics)"
    ],
    "answer": 2,
    "explanation": "**Probability Range**: Probabilities are always between 0 and 1.",
    "id": 119,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "In a normal distribution, approximately what percentage of data falls within $\\pm 1$ standard deviation of the mean?",
    "options": [
      "50%",
      "68%",
      "95%",
      "99.7%"
    ],
    "answer": 1,
    "explanation": "**Normal Distribution**: Symmetric, bell-shaped continuous distribution defined by mean and SD. approx 68% data within 1 SD, 95% within 2 SD.",
    "id": 120,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "The \"Law of Large Numbers\" suggests that:",
    "options": [
      "Larger samples will always have a normal distribution.",
      "As the number of trials increases, the sample mean gets...",
      "You need at least 100 participants for any study.",
      "Smaller samples are more accurate. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Law of Large Numbers**: As sample size increases, sample mean converges to population mean.",
    "id": 121,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "Which R package contains the `z.test` function used in the lectures?",
    "options": [
      "`ggplot2`",
      "`stats`",
      "`BSDA`",
      "`psych`"
    ],
    "answer": 2,
    "explanation": "**z.test package**: `BSDA` package contains `z.test`.",
    "id": 122,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "If a distribution is perfectly symmetric, the mean, median, and mode are:",
    "options": [
      "All different",
      "All equal",
      "Equal to the standard deviation",
      "Equal to 1"
    ],
    "answer": 1,
    "explanation": "**F-distribution**: Used in ANOVA and regression to compare variances or models. Ratio of two chi-squares.",
    "id": 123,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "The sum of probabilities for all possible outcomes in a sample space is:",
    "options": [
      "0",
      "0.5",
      "1.0",
      "Infinite"
    ],
    "answer": 2,
    "explanation": "**Sum of Probabilities**: Sum of all possible outcomes in sample space is 1.",
    "id": 124,
    "module": "Module 1: Introduction & Probability"
  },
  {
    "type": "mc",
    "question": "You want to study \"all undergraduate students.\" You only have access to students at Tilburg University. The Tilburg students represent your:",
    "options": [
      "Target Population",
      "Sample",
      "Parameter",
      "Sampling Frame"
    ],
    "answer": 1,
    "explanation": "**Sample** is defined as: The subset of the population you actually collect data from.",
    "id": 125,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Which sampling method gives every member of the population an equal chance of being selected?",
    "options": [
      "Convenience Sampling",
      "Simple Random Sampling",
      "Snowball Sampling",
      "Quota Sampling"
    ],
    "answer": 1,
    "explanation": "**Simple Random Sampling** is defined as: Every member of population has equal chance of selection.",
    "id": 126,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "A researcher stands outside the cafeteria and asks whoever walks by to answer a survey. This is an example of:",
    "options": [
      "Stratified Sampling",
      "Random Sampling",
      "Opportunity/Convenience Sampling",
      "Systematic Sampling"
    ],
    "answer": 2,
    "explanation": "**Mad Men Example**: Correlation implies causation fallacy or 'Just Drunk' = Spurious/Chance.",
    "id": 127,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Snowball sampling is most useful when:",
    "options": [
      "You want to avoid all bias. (in statistics)",
      "The population is very large and easy to access.",
      "The population is hard to reach (e.g., rare diseases,",
      "You want to ensure equal gender representation."
    ],
    "answer": 2,
    "explanation": "**Snowball Sampling**: Participants recruit others. Useful for hard-to-reach populations.",
    "id": 128,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Stratified sampling involves:",
    "options": [
      "Dividing the population into subgroups (strata) and",
      "Sampling whoever is available. (in statistics)",
      "Asking participants to recruit their friends.",
      "Selecting every $n$-th person from a list."
    ],
    "answer": 0,
    "explanation": "**Stratified Sampling**: Dividing population into strata (subgroups) and sampling from each to ensure representation.",
    "id": 129,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "WEIRD samples, a common source of bias in psychology/CSAI research, stands for:",
    "options": [
      "Western, Educated, Intelligent, Rich, Democratic",
      "Western, Educated, Industrialized, Rich, Democratic",
      "White, European, Industrialized, Rural, Dutch",
      "Western, European, Intellectual, Rich, Developed"
    ],
    "answer": 0,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 130,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "A \"statistic\" describes a \\_\\_\\_\\_\\_\\_\\_, while a \"parameter\" describes a \\_\\_\\_\\_\\_\\_\\_.",
    "options": [
      "Population; Sample",
      "Sample; Population",
      "Mean; Standard Deviation",
      "Hypothesis; Result"
    ],
    "answer": 1,
    "explanation": "**Statistic vs Parameter**: Statistic describes Sample (Latin letters, M, s). Parameter describes Population (Greek letters, , ).",
    "id": 131,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "As the sample size ($N$) increases, the Standard Error of the Mean (SEM):",
    "options": [
      "Increases",
      "Decreases",
      "Stays the same",
      "Becomes equal to the Standard Deviation"
    ],
    "answer": 1,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 132,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "The Central Limit Theorem states that as sample size increases, the sampling distribution of the mean will:",
    "options": [
      "Approach a normal distribution, regardless...",
      "Become more skewed. (in statistics)",
      "Have a larger standard deviation.",
      "Identically match the population distribution."
    ],
    "answer": 0,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 133,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Which symbol represents the *population* mean?",
    "options": [
      "$\\bar{x}$ (x-bar)",
      "$s$",
      "$\\mu$ (mu)",
      "$\\sigma$ (sigma)"
    ],
    "answer": 2,
    "explanation": "**Population Mean Symbol**:  (Mu).",
    "id": 134,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Which symbol represents the *sample* standard deviation?",
    "options": [
      "$\\sigma$",
      "$\\mu$",
      "$s$",
      "$\\beta$"
    ],
    "answer": 2,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 135,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "A 95% Confidence Interval (CI) of [45, 55] means:",
    "options": [
      "There is a 95% chance the sample mean is between 45 and 55.",
      "95% of the data points lie between 45 and 55.",
      "If we replicated the study many times, 95% of the...",
      "The true mean is definitely 50. (in statistics)"
    ],
    "answer": 2,
    "explanation": "**Confidence Interval (CI)**: Interval that captures the true parameter in 95% of repeated samples (for 95% CI). NOT '95% chance parameter is here'.",
    "id": 136,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Sampling *without* replacement means:",
    "options": [
      "Once an individual is selected, they are put back into the pool and can be selected again.",
      "Once an individual is selected, they cannot be selected again.",
      "You replace the participant with a different person if they drop out.",
      "You use a different sampling method halfway through."
    ],
    "answer": 1,
    "explanation": "**Sampling Without Replacement**: Individuals cannot be selected twice.",
    "id": 137,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Which of the following scenarios is most likely to produce a *biased* sample for a study on \"Global internet usage\"?",
    "options": [
      "Randomly selecting IP addresses from every country.",
      "Posting a survey link only on a VR gaming forum.",
      "Using a stratified sample based on continent population.",
      "Using a random digit dialer for phone numbers worldwide."
    ],
    "answer": 1,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 138,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "If you replicate a study 20 times, how many of the 95% confidence intervals would you expect to *miss* (not include) the true population mean?",
    "options": [
      "0",
      "1",
      "5",
      "10"
    ],
    "answer": 1,
    "explanation": "**Population Mean Symbol**:  (Mu).",
    "id": 139,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "We use sample statistics to \\_\\_\\_\\_\\_\\_\\_ population parameters.",
    "options": [
      "Prove",
      "Define",
      "Estimate",
      "Correlate"
    ],
    "answer": 2,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 140,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Standard Error is calculated as:",
    "options": [
      "$SD / N$",
      "$SD / \\sqrt{N}$",
      "$Mean / SD$",
      "$SD^2$"
    ],
    "answer": 1,
    "explanation": "**Standard Error (SEM)**: SD of the sampling distribution of the mean. `SEM = SD / sqrt(N)`. Decreases as N increases.",
    "id": 141,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "What is the primary goal of inferential statistics in CSAI?",
    "options": [
      "To describe the sample data perfectly. approach",
      "To use sample data to make generalizations about a...",
      "To calculate the mean of a population directly.",
      "To eliminate all sampling error. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Goal of Inferential Stats**: Generalize from sample to population.",
    "id": 142,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Which R function was used in the lecture to calculate confidence intervals for the mean?",
    "options": [
      "`meanCI()` methodology",
      "`ciMean()` (from `lsr`...",
      "`confint()` methodology",
      "`get_CI()` methodology"
    ],
    "answer": 1,
    "explanation": "**cor() function**: Calculates correlation in R.",
    "id": 143,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "If your sampling distribution of the mean is very wide (large standard error), it implies:",
    "options": [
      "Your estimate of the population mean is very precise.",
      "Your sample size is likely very large.",
      "Your estimate of the population mean is imprecise.",
      "You made a calculation error."
    ],
    "answer": 2,
    "explanation": "**F-distribution**: Used in ANOVA and regression to compare variances or models. Ratio of two chi-squares.",
    "id": 144,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Bias in sampling occurs when:",
    "options": [
      "The sample size is too small. methodology",
      "The sample does not accurately reflect the...",
      "You use random sampling. (in statistics)",
      "You calculate the mean instead of the median."
    ],
    "answer": 1,
    "explanation": "**Sampling Bias**: Systematic error where sample does not represent population.",
    "id": 145,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "If you increase your sample size from 50 to 500, the confidence interval will likely:",
    "options": [
      "Become wider. approach",
      "Become narrower (more pr...",
      "Stay the same. approach",
      "Disappear. methodology"
    ],
    "answer": 1,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 146,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "In the \"Taco Literacy\" example from the lecture, finding that 72% of 1000 people are taco illiterate vs 43% of 10,000 people suggests:",
    "options": [
      "The first sample was likely biased or",
      "Taco literacy decreased over time.",
      "The standard deviation increased. approach",
      "The population parameter changed. approach"
    ],
    "answer": 0,
    "explanation": "**Taco Literacy Example**: Large discrepancies in percentages between samples suggest Sampling Variance or Bias.",
    "id": 147,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "Which of the following is NOT a type of non-probability sampling?",
    "options": [
      "Convenience Sampling",
      "Snowball Sampling",
      "Simple Random Sampling",
      "Volunteer Sampling"
    ],
    "answer": 2,
    "explanation": "**Non-probability Sampling**: Convenience, Snowball, Quota. (Random is Probability sampling).",
    "id": 148,
    "module": "Module 2: Sampling Theory"
  },
  {
    "type": "mc",
    "question": "The Null Hypothesis ($H_0$) usually states that:",
    "options": [
      "There is a strong relationship between variables.",
      "There is no effect, no difference, or the relationship...",
      "The alternative hypothesis is false. methodology",
      "The sample mean equals the sample median. approach"
    ],
    "answer": 1,
    "explanation": "**Null Hypothesis (H0)**: Assumption of No Effect, No Difference, or r = 0.",
    "id": 149,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "A Type I error occurs when:",
    "options": [
      "You reject the null hypothesis when it is actually true...",
      "You fail to reject the null hypothesis when it is actually false (False Negative).",
      "Your sample size is too small. (additional contex",
      "You use a T-test instead of a Z-test. (in statistics)"
    ],
    "answer": 0,
    "explanation": "**Type I Error (Alpha)**: False Positive. Rejecting H0 when it's True. Risk = .",
    "id": 150,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "A Type II error occurs when:",
    "options": [
      "You reject the null hypothesis when it is true.",
      "You fail to reject the null hypothesis when...",
      "The p-value is less than 0.05. methodology",
      "The effect size is large. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Type I Error (Alpha)**: False Positive. Rejecting H0 when it's True. Risk = .",
    "id": 151,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "If your calculated p-value is 0.03 and your alpha level ($\\alpha$) is 0.05, you should:",
    "options": [
      "Fail to reject the null hypothesis.",
      "Reject the null hypothesis.",
      "Change your alpha level to 0.01.",
      "Conclude the null hypothesis is definitely true."
    ],
    "answer": 1,
    "explanation": "**Alpha Level**: Typically 0.05.",
    "id": 152,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "Which test statistic should be used when the population standard deviation ($\\sigma$) is *unknown*?",
    "options": [
      "Z-statistic",
      "T-statistic",
      "F-statistic",
      "Chi-square statistic"
    ],
    "answer": 1,
    "explanation": "**Test for Unknown Sigma**: T-test (uses sample s instead of population ).",
    "id": 153,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "Cohens d is a measure of:",
    "options": [
      "Statistical significance",
      "Effect size (standardized mean...",
      "Variance explained approach",
      "Sampling error methodology"
    ],
    "answer": 1,
    "explanation": "**Cohen's d**: Effect size for means. Standardized difference. 0.2 small, 0.5 medium, 0.8 large.",
    "id": 154,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "A Cohens d of 0.8 is generally considered a:",
    "options": [
      "Small effect",
      "Medium effect",
      "Large effect",
      "Trivial effect"
    ],
    "answer": 2,
    "explanation": "**Cohen's d**: Effect size for means. Standardized difference. 0.2 small, 0.5 medium, 0.8 large.",
    "id": 155,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "To calculate a p-value, you do NOT need to know:",
    "options": [
      "The value of the test statistic",
      "The degrees of freedom (for t-tests)",
      "Whether the test is one-tailed or two-tailed",
      "The alpha level ($\\alpha$)"
    ],
    "answer": 3,
    "explanation": "**Expected Value vs Observation**: Differences between observed data and expected value are due to sampling error (chance), assuming H0 is true.",
    "id": 156,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "If you perform multiple statistical tests (e.g., 20 t-tests) on the same data, you increase the risk of:",
    "options": [
      "Type II error approach",
      "Type I error (Family-wise...",
      "Standard error approach",
      "Sampling bias approach"
    ],
    "answer": 1,
    "explanation": "**Distributions for Categorical Data**: Chi-square is often used for categorical/count data analysis.",
    "id": 157,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "Which correction is commonly used to control for the Family-Wise Error Rate when making multiple comparisons?",
    "options": [
      "Pearson correction",
      "Bonferroni correction",
      "Spearman correction",
      "Gaussian correction"
    ],
    "answer": 1,
    "explanation": "**Multiple Comparisons**: Increases Family-wise Error Rate (risk of at least one Type I error).",
    "id": 158,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "Which of the following indicates the *strongest* evidence against the null hypothesis?",
    "options": [
      "p = 0.05",
      "p = 0.50",
      "p = 0.001",
      "p = 0.10"
    ],
    "answer": 2,
    "explanation": "**Null Hypothesis (H0)**: Assumption of No Effect, No Difference, or r = 0.",
    "id": 159,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "Statistical Power is defined as:",
    "options": [
      "The probability of rejecting a false null hypothes...",
      "The probability of making a Type I error.",
      "The size of the effect. (in statistics)",
      "The standard deviation of the sampling distribution."
    ],
    "answer": 0,
    "explanation": "**Statistical Power**: Probability of correctly rejecting false H0. Power = 1 - .",
    "id": 160,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "In a two-tailed test with $\\alpha = 0.05$, the critical region contains:",
    "options": [
      "The top 5% of the distribution. methodology",
      "The bottom 5% of the distribution.",
      "The extreme 2.5% on both ends of the distribu...",
      "The middle 95% of the distribution."
    ],
    "answer": 2,
    "explanation": "**Critical Region**: The area in the tails where we reject H0. Split between tails for 2-tailed.",
    "id": 161,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "Why do T-distributions have \"heavier tails\" than the Z-distribution?",
    "options": [
      "Because they are skewed. (in statistics)",
      "To account for the extra uncertainty introduced...",
      "Because they are used for large sample sizes.",
      "Because they are used for binary data."
    ],
    "answer": 1,
    "explanation": "**F-distribution**: Used in ANOVA and regression to compare variances or models. Ratio of two chi-squares.",
    "id": 162,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "Which R function performs a t-test?",
    "options": [
      "`z.test()`",
      "`t.test()`",
      "`cor.test()`",
      "`lm()`"
    ],
    "answer": 1,
    "explanation": "**t.test()**: Function for T-test in R.",
    "id": 163,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "If a 95% Confidence Interval for a mean difference includes 0 (e.g., [-2, 5]), what can you conclude?",
    "options": [
      "The difference is statistically significant at p < 0.05.",
      "The difference is NOT statistically significant...",
      "The effect size is large. (in statistics)",
      "You have made a Type I error. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Confidence Interval (CI)**: Interval that captures the true parameter in 95% of repeated samples (for 95% CI). NOT '95% chance parameter is here'.",
    "id": 164,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "A hypothesis that predicts a specific direction (e.g., \"Group A will score *higher* than Group B\") requires a:",
    "options": [
      "Two-tailed test",
      "One-tailed test",
      "Null test",
      "Bonferroni correction"
    ],
    "answer": 1,
    "explanation": "**Null Hypothesis (H0)**: Assumption of No Effect, No Difference, or r = 0.",
    "id": 165,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "The \"Alternative Hypothesis\" ($H_1$) usually corresponds to:",
    "options": [
      "The status quo. approach",
      "The research prediction (e.g.,",
      "A calculation error.",
      "The alpha level. approach"
    ],
    "answer": 1,
    "explanation": "**Alternative Hypothesis (H1)**: The research hypothesis (There is an effect).",
    "id": 166,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "Which package was used in the slides to calculate Cohen's d?",
    "options": [
      "`ggplot2` methodology",
      "`psych` (specifical...",
      "`stats` (in statistics)",
      "`lsr` (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Cohen's d**: Effect size for means. Standardized difference. 0.2 small, 0.5 medium, 0.8 large.",
    "id": 167,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "If you have a very large sample size, even very small effects can become:",
    "options": [
      "Statistically significant",
      "Practically significant",
      "Non-significant",
      "Biased"
    ],
    "answer": 0,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 168,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "The threshold for statistical significance ($\\alpha$) is typically set to:",
    "options": [
      "0.01",
      "0.05",
      "0.10",
      "0.50"
    ],
    "answer": 1,
    "explanation": "**Type I Error (Alpha)**: False Positive. Rejecting H0 when it's True. Risk = .",
    "id": 169,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "The \"p-value\" represents:",
    "options": [
      "The probability that the Null Hypothesis is true.",
      "The probability of obtaining the observed data (or more...",
      "The probability that the Alternative Hypothesis is true.",
      "The probability of making a Type I error. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Expected Value vs Observation**: Differences between observed data and expected value are due to sampling error (chance), assuming H0 is true.",
    "id": 170,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "In the \"Mad Men\" example from the slides, the conclusion \"Nope, just super drunk\" implies:",
    "options": [
      "The hypothesis was supported.",
      "The hypothesis was rejected (Null...",
      "The correlation was 1.0. approach",
      "A Type I error occurred. approach"
    ],
    "answer": 1,
    "explanation": "**Mad Men Example**: Correlation implies causation fallacy or 'Just Drunk' = Spurious/Chance.",
    "id": 171,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "When reporting a t-test, you should include:",
    "options": [
      "The t-value",
      "The degrees of freedom",
      "The p-value",
      "All of the above"
    ],
    "answer": 3,
    "explanation": "**t.test()**: Function for T-test in R.",
    "id": 172,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "If you run a Z-test in R using `BSDA::z.test`, you must calculate or know \\_\\_\\_\\_\\_\\_ beforehand.",
    "options": [
      "The sample mean only.",
      "The population standard deviatio...",
      "The p-value. (in statistics)",
      "The correlation coefficient."
    ],
    "answer": 1,
    "explanation": "**t.test()**: Function for T-test in R.",
    "id": 173,
    "module": "Module 3: Hypothesis Testing"
  },
  {
    "type": "mc",
    "question": "The Pearson correlation coefficient ($r$) ranges from:",
    "options": [
      "0 to 1",
      "-1 to 1",
      "-100 to 100",
      "$-\\infty$ to $+\\infty$"
    ],
    "answer": 1,
    "explanation": "**Pearson's r Range**: -1 to +1.",
    "id": 174,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "If $r = -0.90$, this indicates:",
    "options": [
      "A weak negative relationship.",
      "A strong positive relationship.",
      "A strong negative relationship.",
      "No relationship."
    ],
    "answer": 2,
    "explanation": "Answer derived from course materials (Module 1-4).",
    "id": 175,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which of the following is TRUE about correlation?",
    "options": [
      "Correlation implies causation. (additional context",
      "A correlation of 0 means there is definitely no relationship (linear or non-linear).",
      "Correlation measures the strength and direction of a linear...",
      "Pearson's $r$ is robust to outliers. (in statistics)"
    ],
    "answer": 2,
    "explanation": "**Strong Correlation**: Closer to -1 or +1. 0.85 is Strong.",
    "id": 176,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Covariance differs from correlation because:",
    "options": [
      "Covariance is standardized. (in statistics)",
      "Covariance depends on the units of measuremen...",
      "Covariance is always between -1 and 1.",
      "Covariance is used for ordinal data."
    ],
    "answer": 1,
    "explanation": "**Covariance**: Unstandardized measure of joint variability. Hard to interpret magnitude.",
    "id": 177,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "To standardize covariance and turn it into a correlation coefficient, you divide it by:",
    "options": [
      "The sample size ($N$). methodology",
      "The product of the standard deviations...",
      "The mean of the variables.",
      "The variance of the variables."
    ],
    "answer": 1,
    "explanation": "**Covariance**: Unstandardized measure of joint variability. Hard to interpret magnitude.",
    "id": 178,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Calculating $r^2$ (the coefficient of determination) tells you:",
    "options": [
      "The direction of the relationship.",
      "The proportion of variance in one variable...",
      "The statistical significance of the relationship.",
      "The causal effect. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Partial Coefficient**: Slope of X1 holding X2 constant.",
    "id": 179,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "If data are ordinal (ranked) or contain outliers, which correlation coefficient is most appropriate?",
    "options": [
      "Pearson's $r$",
      "Spearman's $\\rho$ (rho)",
      "Point-biserial correlation",
      "Partial correlation"
    ],
    "answer": 1,
    "explanation": "**Distributions for Categorical Data**: Chi-square is often used for categorical/count data analysis.",
    "id": 180,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "A Partial Correlation between X and Y, controlling for Z, removes the influence of Z from:",
    "options": [
      "Only X",
      "Only Y",
      "Both X and Y",
      "Neither"
    ],
    "answer": 2,
    "explanation": "**Partial Correlation**: Correlation between X and Y controlling for Z on BOTH.",
    "id": 181,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "A Semi-Partial Correlation between X and Y, controlling for Z, removes the influence of Z from:",
    "options": [
      "Only one of the variables (usua...",
      "Both X and Y. (in statistics)",
      "The outcome variable only.",
      "The error term only."
    ],
    "answer": 0,
    "explanation": "**Partial Correlation**: Correlation between X and Y controlling for Z on BOTH.",
    "id": 182,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "In R, which function performs a correlation test and provides a p-value?",
    "options": [
      "`cor()`",
      "`cor.test()`",
      "`cov()`",
      "`mean()`"
    ],
    "answer": 1,
    "explanation": "**t.test()**: Function for T-test in R.",
    "id": 183,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which assumption is NOT required for Pearsons correlation?",
    "options": [
      "Linearity",
      "Interval or Ratio data",
      "Normality (for significance testing)",
      "Homogeneity of regression slopes"
    ],
    "answer": 3,
    "explanation": "**Pearson's r Range**: -1 to +1.",
    "id": 184,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "\"Spurious correlations\" (like ice cream sales and shark attacks) usually occur due to:",
    "options": [
      "A third variable (confounder)...",
      "Small sample sizes. approach",
      "Type II errors. methodology",
      "Non-linear relationships."
    ],
    "answer": 0,
    "explanation": "**Spurious Correlation**: Third variable causes relationship (e.g. Ice cream & Shark attacks).",
    "id": 185,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "If you run `cor.test(x, y, alternative = \"greater\")`, you are testing:",
    "options": [
      "A two-tailed hypothesis ($r \\neq 0$). (in statistics)",
      "A one-tailed hypothesis that the correlation is positive...",
      "A one-tailed hypothesis that the correlation is negative ($r < 0$).",
      "The null hypothesis that $r = 0$. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**t.test()**: Function for T-test in R.",
    "id": 186,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "What is the effect size of a correlation where $r = 0.10$?",
    "options": [
      "Large",
      "Medium",
      "Small",
      "Zero"
    ],
    "answer": 2,
    "explanation": "**r = 0**: No LINEAR relationship (could be U-shaped).",
    "id": 187,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Kendalls tau ($\\tau$) is generally preferred over Spearmans rho when:",
    "options": [
      "The sample size is small.",
      "The data is normally distributed.",
      "The sample size is very large.",
      "The data is ratio scale."
    ],
    "answer": 0,
    "explanation": "**Spearman's Rho**: Non-parametric rank correlation. Good for outliers or ordinal data.",
    "id": 188,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "In the lecture example about exam anxiety, exam performance, and revision time, a Partial correlation was used to:",
    "options": [
      "See the relationship between Exam and",
      "See if Anxiety causes poor performance.",
      "Calculate the mean of the exam scores.",
      "Rank the students. (in statistics)"
    ],
    "answer": 0,
    "explanation": "**Partial Correlation**: Correlation between X and Y controlling for Z on BOTH.",
    "id": 189,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which R package contains the `pcor.test` function for partial correlations?",
    "options": [
      "`stats`",
      "`ppcor`",
      "`psych`",
      "`lsr`"
    ],
    "answer": 1,
    "explanation": "**Partial Correlation**: Correlation between X and Y controlling for Z on BOTH.",
    "id": 190,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "If you see a correlation matrix where the diagonal values are all 1.0, this is because:",
    "options": [
      "Every variable is perfectly correlat...",
      "The calculation is wrong.",
      "The p-values are 1.0. methodology",
      "There is multicollinearity."
    ],
    "answer": 0,
    "explanation": "**Correlation Matrix**: Table of correlations between all pairs.",
    "id": 191,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which visual plot is best for checking the assumption of linearity before running a correlation?",
    "options": [
      "Histogram",
      "Boxplot",
      "Scatterplot",
      "Bar chart"
    ],
    "answer": 2,
    "explanation": "**Scatterplot** is defined as: Best plot to visualize correlation.",
    "id": 192,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "If the covariance between two variables is 4.25, what can you definitely say about the relationship?",
    "options": [
      "It is strong.",
      "It is weak.",
      "It is positive.",
      "It is statistically significant."
    ],
    "answer": 2,
    "explanation": "**Covariance**: Unstandardized measure of joint variability. Hard to interpret magnitude.",
    "id": 193,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "In the \"Guess the Correlation\" game mentioned in class, a dispersed cloud of points with no clear slope indicates:",
    "options": [
      "High positive correlation.",
      "High negative correlation.",
      "Correlation near 0.",
      "A calculation error."
    ],
    "answer": 2,
    "explanation": "**Slope (b1)**: Change in Y for 1 unit increase in X.",
    "id": 194,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Can a correlation coefficient ever be greater than 1?",
    "options": [
      "Yes, if the effect size is huge.",
      "No, it is mathematically impossible.",
      "Yes, if you use Spearman's rho.",
      "Yes, if you don't standardize."
    ],
    "answer": 1,
    "explanation": "**Strong Correlation**: Closer to -1 or +1. 0.85 is Strong.",
    "id": 195,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "If variable X increases and variable Y decreases, the correlation is:",
    "options": [
      "Positive",
      "Negative",
      "Zero",
      "Spurious"
    ],
    "answer": 1,
    "explanation": "**Strong Correlation**: Closer to -1 or +1. 0.85 is Strong.",
    "id": 196,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which R function allows you to calculate a correlation matrix for multiple variables at once?",
    "options": [
      "`cor()`",
      "`t.test()`",
      "`mean()`",
      "`summary()`"
    ],
    "answer": 0,
    "explanation": "**Correlation Matrix**: Table of correlations between all pairs.",
    "id": 197,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "The `easystats` / `correlation` package mentioned in the slides is useful because:",
    "options": [
      "It does the homework for you.",
      "It provides a convenient way to visualize and report complex correlation matrices.",
      "It only calculates Pearson correlations.",
      "It does not require R."
    ],
    "answer": 0,
    "explanation": "**z.test package**: The `easystats` / `correlation` package provides a convenient way to visualize and report complex correlation matrices.",
    "id": 198,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "A researcher finds a covariance of 120 between variable X and Y. The standard deviation of X is 10 and the standard deviation of Y is 15. What is the Pearson correlation coefficient ($r$)?",
    "options": [
      "0.80",
      "1.20",
      "0.12",
      "0.85"
    ],
    "answer": 0,
    "explanation": "**Covariance**: Unstandardized measure of joint variability. Hard to interpret magnitude.\n\nAnswer Key: $r = \\frac{cov(X,Y)}{sd(X)sd(Y)} = \\frac{120}{10 \\times 15} = \\frac{120}{150} = 0.8$",
    "id": 199,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which of the following correlation coefficients indicates the strongest relationship?",
    "options": [
      "$r = 0.65$",
      "$r = -0.72$",
      "$r = 0.10$",
      "$r = -0.05$"
    ],
    "answer": 1,
    "explanation": "**Strong Correlation**: Closer to -1 or +1. 0.85 is Strong.\n\nAnswer Key: Magnitude $|-0.72| = 0.72$ is the highest",
    "id": 200,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "You want to examine the relationship between `age` and `reaction_time` while controlling for the effect of `hours_slept` on both variables. Which type of correlation should you use?",
    "options": [
      "Semi-partial correlation",
      "Point-biserial correlation",
      "Partial correlation",
      "Spearman's rank correlation"
    ],
    "answer": 2,
    "explanation": "**Type I Error (Alpha)**: False Positive. Rejecting H0 when it's True. Risk = .",
    "id": 201,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "A Spearman correlation is most appropriate when:",
    "options": [
      "The relationship between variables is linear and data are normally distributed.",
      "The sample size is large (\\>100) and data are ratio scale. methodology",
      "The data are ordinal (ranked) or the relationship is monotonic but",
      "You want to predict the exact value of Y from X. (in statistics)"
    ],
    "answer": 2,
    "explanation": "**Spearman's Rho**: Non-parametric rank correlation. Good for outliers or ordinal data.",
    "id": 202,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which of the following is TRUE about the coefficient of determination ($R^2$) in a simple correlation context?",
    "options": [
      "It represents the percent of variance in one variable shared...",
      "It can be negative if the correlation is negative.",
      "It is the square root of the correlation coefficient.",
      "It tells you the direction of the relationship. methodology"
    ],
    "answer": 0,
    "explanation": "**Simple Random Sampling**: Every member of population has equal chance of selection.",
    "id": 203,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "If $r = 0.50$, how much variance in Variable Y is explained by Variable X?",
    "options": [
      "50%",
      "5%",
      "25%",
      "100%"
    ],
    "answer": 2,
    "explanation": "**r = 0**: No LINEAR relationship (could be U-shaped).\n\nAnswer Key: $0.50^2 = 0.25$",
    "id": 204,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which R function would you use to calculate a correlation matrix for a data frame `df`?",
    "options": [
      "`summary(df)`",
      "`cor(df)`",
      "`lm(df)`",
      "`t.test(df)`"
    ],
    "answer": 1,
    "explanation": "**Correlation Matrix**: Table of correlations between all pairs.",
    "id": 205,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Interpreting Output:\n**Based on the output above, which conclusion is correct?**",
    "options": [
      "There is a significant positive relationship between stress and performance.",
      "There is a significant negative relationship; as stress increases,",
      "The relationship is not statistically significant ($p > .05$).",
      "Stress causes poor performance. (additional context) (ad"
    ],
    "answer": 1,
    "explanation": "Check the R output to identify the correct correlation coefficient and p-value.",
    "id": 206,
    "codeSnippet": "> cor.test(df$stress, df$performance)",
    "codeOutput": "Pearson's product-moment correlation\n\ndata:  df$stress and df$performance\nt = -4.52, df = 98, p-value = 0.000017\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n-0.584321 -0.239812\nsample estimates:\ncor\n-0.4156",
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "What is the null hypothesis for a standard Pearson correlation test?",
    "options": [
      "$r = 1$ (in statistics)",
      "$r \\neq 0$ methodology",
      "$\\rho = 0$ (The popula...",
      "$\\mu_1 = \\mu_2$"
    ],
    "answer": 2,
    "explanation": "**Null Hypothesis (H0)**: Assumption of No Effect, No Difference, or r = 0.",
    "id": 207,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Semi-partial correlation differs from partial correlation because:",
    "options": [
      "It controls for a third variable on *both* the predictor and criterion.",
      "It controls for a third variable on *only* the predictor (or only...",
      "It is used only for non-parametric data. (in statistics)",
      "It yields a higher value than the zero-order correlation."
    ],
    "answer": 1,
    "explanation": "**Partial Correlation**: Correlation between X and Y controlling for Z on BOTH.",
    "id": 208,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which assumption is NOT required for Pearson correlation?",
    "options": [
      "Linearity",
      "Normality of variables",
      "Homoscedasticity",
      "Multicollinearity"
    ],
    "answer": 3,
    "explanation": "**Pearson's r Range**: -1 to +1.",
    "id": 209,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "You have a small sample size ($N=8$) and your data contains outliers. Which correlation coefficient is robust to outliers?",
    "options": [
      "Pearson's $r$",
      "Spearman's $\\rho$ (rho)",
      "Point-biserial $r_{pb}$",
      "$R^2$"
    ],
    "answer": 1,
    "explanation": "**Sample**: The subset of the population you actually collect data from.",
    "id": 210,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "A correlation of $r = 0$ implies:",
    "options": [
      "No relationship exists between the variables.",
      "No *linear* relationship exists between...",
      "The variables are independent. approach",
      "The covariance is 1. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**r = 0**: No LINEAR relationship (could be U-shaped).",
    "id": 211,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "If you run `cor.test()` and get a confidence interval of $[-0.10, 0.35]$, what can you conclude?",
    "options": [
      "The true correlation is likely 0.35. methodology",
      "The correlation is statistically significant.",
      "The correlation is not statistically significant...",
      "There is a strong negative relationship. approach"
    ],
    "answer": 2,
    "explanation": "**cor.test()**: Tests significance of correlation.",
    "id": 212,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "Which library in R contains the `pcor()` function for partial correlations?",
    "options": [
      "`ggplot2`",
      "`ppcor`",
      "`stats`",
      "`dplyr`"
    ],
    "answer": 1,
    "explanation": "**Partial Correlation**: Correlation between X and Y controlling for Z on BOTH.",
    "id": 213,
    "module": "Module 4: Correlation"
  },
  {
    "type": "mc",
    "question": "In the simple linear regression equation $Y_i = b_0 + b_1X_i + \\epsilon_i$, what does $b_0$ represent?",
    "options": [
      "The slope of the line. approach",
      "The residual error. methodology",
      "The Y-intercept (value of Y when X...",
      "The standardized coefficient."
    ],
    "answer": 2,
    "explanation": "**Regression Equation**: Y = b0 + b1*X + e. Intercept + Slope.\n\nAnswer Key: The intercept b_0 represents the predicted value of Y when X is 0.",
    "id": 214,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "The method used to estimate regression coefficients by minimizing the sum of squared residuals is called:",
    "options": [
      "Maximum Likelihood Estimation.",
      "Ordinary Least Squares (OLS).",
      "Bayesian Estimation.",
      "Standard Deviation Minimization."
    ],
    "answer": 1,
    "explanation": "**Residual**: Observed Y - Predicted Y.",
    "id": 215,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Interpreting Output:\n**Based on this output, what is the predicted exam score for a student with an anxiety score of 4?**",
    "options": [
      "82.5",
      "75.0",
      "95.0",
      "85.0"
    ],
    "answer": 1,
    "explanation": "Answer Key: $85 + (-2.5 \\times 4) = 75$",
    "id": 216,
    "codeSnippet": "Call:\nlm(formula = exam_score ~ anxiety, data = students)",
    "codeOutput": "Coefficients:\n(Intercept)      anxiety\n85.00        -2.50",
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "What is the residual ($e_i$) for a data point?",
    "options": [
      "The difference between the observed Y and the predicted...",
      "The difference between the observed X and the mean of X.",
      "The distance from the intercept to the data point.",
      "The variance of the model. (additional conte"
    ],
    "answer": 0,
    "explanation": "**Residual**: Observed Y - Predicted Y.",
    "id": 217,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Which R code correctly runs a simple linear regression predicting `sales` from `adverts`?",
    "options": [
      "`lm(sales ~ adverts, data = df)`",
      "`lm(adverts ~ sales, data = df)`",
      "`cor(sales, adverts)`",
      "`plot(sales, adverts)`"
    ],
    "answer": 0,
    "explanation": "**Simple Random Sampling**: Every member of population has equal chance of selection.",
    "id": 218,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "In the output of `summary(model)`, the t-test associated with the slope ($b_1$) tests which null hypothesis?",
    "options": [
      "$b_1 = 1$",
      "$b_1 = 0$",
      "$b_0 = 0$",
      "The model explains 0% of the variance."
    ],
    "answer": 1,
    "explanation": "**summary(model)**: Shows coefficients, R2, F-test.",
    "id": 219,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "If the F-statistic in a simple regression is significant ($p < .05$), this means:",
    "options": [
      "The intercept is not zero. approach",
      "The model explains significantly more...",
      "The relationship is non-linear.",
      "Homoscedasticity is met. methodology"
    ],
    "answer": 1,
    "explanation": "**F-statistic**: Tests if whole model is better than null model.",
    "id": 220,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Total Sum of Squares ($SS_T$) represents:",
    "options": [
      "The error in the regression model. (in statistics)",
      "The improvement of the regression model over the mean.",
      "The total variability in the outcome variable...",
      "The sum of the squared residuals. (in statistics)"
    ],
    "answer": 2,
    "explanation": "**R-squared**:  (Related to SS_T).",
    "id": 221,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Which metric represents the average deviation of the residuals (in the units of the outcome variable)?",
    "options": [
      "$R^2$ (in statistics)",
      "F-statistic methodology",
      "Residual Standard Erro...",
      "Adjusted $R^2$ approach"
    ],
    "answer": 2,
    "explanation": "**Residual**: Observed Y - Predicted Y.",
    "id": 222,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "If $SS_{Model} = 40$ and $SS_{Total} = 100$, what is $R^2$?",
    "options": [
      "0.60",
      "0.40",
      "2.5",
      "4000"
    ],
    "answer": 1,
    "explanation": "**summary(model)**: Shows coefficients, R2, F-test.\n\nAnswer Key: $40/100$",
    "id": 223,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Interpreting Output:\n**What is the 95% Confidence Interval for the slope of `hours_study` (approximate using $t \\approx 2$)?**",
    "options": [
      "$[3.00, 7.00]$",
      "$[8.00, 12.00]$",
      "$[4.00, 6.00]$",
      "$[0.00, 10.00]$"
    ],
    "answer": 0,
    "explanation": "**Confidence Interval (CI)**: Interval that captures the true parameter in 95% of repeated samples (for 95% CI). NOT '95% chance parameter is here'.\n\nAnswer Key: $5 \\pm 2(1)$",
    "id": 224,
    "codeSnippet": "Coefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)  10.000      2.000   5.000  0.001 ** hours_study   5.000      1.000   5.000  0.001 **",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Standardized regression coefficients ($\\beta$) allow you to:",
    "options": [
      "Interpret the effect in raw units.",
      "Compare the strength of predictors measu...",
      "Ignore the intercept. (in statistics)",
      "Calculate the p-value manually."
    ],
    "answer": 1,
    "explanation": "**Standardized Regression**: Mean=0, SD=1 for all vars.",
    "id": 225,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Which package in R is commonly used to obtain standardized coefficients (`std.beta`)?",
    "options": [
      "`ggplot2` methodology",
      "`effectsize` or `Qua...",
      "`readr` (in statistics)",
      "`tibble` (in statistics)"
    ],
    "answer": 1,
    "explanation": "**z.test package**: `BSDA` package contains `z.test`.",
    "id": 226,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "In a plot of Fitted Values vs. Residuals, a \"fan\" shape indicates a violation of:",
    "options": [
      "Linearity",
      "Independence",
      "Homoscedasticity",
      "Normality"
    ],
    "answer": 2,
    "explanation": "**Residual**: Observed Y - Predicted Y.",
    "id": 227,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Why is the intercept sometimes meaningless in interpreting data?",
    "options": [
      "Because it is always zero. (in statistics)",
      "Because a predictor value of 0 might be impossib...",
      "Because it has a large standard error.",
      "Because it is not a standardized coefficient."
    ],
    "answer": 1,
    "explanation": "**Intercept (b0)**: Predicted Y when X = 0.",
    "id": 228,
    "module": "Module 5: Intro to Regression (Simple Linear)"
  },
  {
    "type": "mc",
    "question": "Centering a predictor variable ($X_{centered} = X - \\bar{X}$) changes which parameter in the regression model?",
    "options": [
      "The slope ($b_1$)",
      "The residual standard error",
      "The intercept ($b_0$)",
      "The $R^2$"
    ],
    "answer": 2,
    "explanation": "**Centering**: Essential for raw polynomials to reduce multicollinearity.",
    "id": 229,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "After centering `age` to the mean, the intercept represents:",
    "options": [
      "The predicted Y when age is 0.",
      "The predicted Y for a person with...",
      "The average age of the sample.",
      "The slope of age. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Centering**: Essential for raw polynomials to reduce multicollinearity.",
    "id": 230,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Which diagnostic plot is best for checking the assumption of **Normality of Residuals**?",
    "options": [
      "Residuals vs. Fitted",
      "Scale-Location",
      "Normal Q-Q Plot",
      "Cooks Distance"
    ],
    "answer": 2,
    "explanation": "**Residual**: Observed Y - Predicted Y.",
    "id": 231,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Influential data points that have a disproportionate impact on the regression line are best detected using:",
    "options": [
      "The histogram of residuals.",
      "Cooks Distance or Leverage vs.",
      "The $R^2$ value. methodology",
      "The F-statistic. methodology"
    ],
    "answer": 1,
    "explanation": "**Distributions for Categorical Data**: Chi-square is often used for categorical/count data analysis.",
    "id": 232,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "If the **Linearity** assumption is violated, the Residuals vs. Fitted plot will look like:",
    "options": [
      "A random cloud of points around 0.",
      "A distinct curve (e.g., U-shape).",
      "A funnel or fan shape.",
      "Points falling exactly on a straight line."
    ],
    "answer": 1,
    "explanation": "**Residual**: Observed Y - Predicted Y.",
    "id": 233,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "The `gvlma()` function from the `gvlma` package performs:",
    "options": [
      "A global validation of linear model assumptions.",
      "A generalized linear model analysis.",
      "A graphical visualization of linear models.",
      "A calculation of standardized betas."
    ],
    "answer": 0,
    "explanation": "**cor() function**: Calculates correlation in R.",
    "id": 234,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Interpreting Output:\n**What does this output suggest?**",
    "options": [
      "The model assumptions are acceptable.",
      "At least one regression assumption has been...",
      "The model is a perfect fit. methodology",
      "You should proceed without changes."
    ],
    "answer": 1,
    "explanation": "Interpret the coefficients and significance levels from the summary output.",
    "id": 235,
    "codeSnippet": "> gvlma(model)",
    "codeOutput": "...\nGlobal Stat        Value   p-value  Decision\n12.5    0.012    Assumptions NOT satisfied!",
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Which assumption cannot be checked just by looking at a plot of the model residuals?",
    "options": [
      "Normality methodology",
      "Linearity methodology",
      "Independence of observa...",
      "Homoscedasticity"
    ],
    "answer": 2,
    "explanation": "**Residual**: Observed Y - Predicted Y.\n\nAnswer Key: Need to know study design",
    "id": 236,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Independence of errors is usually violated when:",
    "options": [
      "The sample size is small. methodology",
      "Data are collected from the same subjects...",
      "The variables are not normally distributed.",
      "There are outliers. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Independence Violation**: Clustered/Time-series data violates this.",
    "id": 237,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Using `check_model()` from the `performance` package generates:",
    "options": [
      "A summary table of coefficients.",
      "A dashboard of visual plots checking...",
      "A new regression model with better fit.",
      "The AIC score. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**z.test package**: `BSDA` package contains `z.test`.",
    "id": 238,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "`dfbeta` statistics are used to:",
    "options": [
      "Calculate degrees of freedom.",
      "Assess how much regression coefficient...",
      "Standardize the betas. methodology",
      "Test for heteroscedasticity."
    ],
    "answer": 1,
    "explanation": "**DFBETAS**: Change in ONE coefficient if case removed.",
    "id": 239,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Interpreting Output (Dummy Coding):\n**If `groupControl` is the reference group (0) and `groupTreatment` is 1, what is the mean of the Treatment group?**",
    "options": [
      "10.0",
      "40.0",
      "50.0",
      "60.0"
    ],
    "answer": 3,
    "explanation": "**Dummy Coding**: 0s and 1s. k-1 dummies for k levels.\n\nAnswer Key: $Intercept + Slope = 50 + 10 = 60$",
    "id": 240,
    "codeSnippet": "Coefficients:\n               Estimate\n(Intercept)    50.0\ngroupTreatment 10.0",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "In R, if you have a categorical variable `Status` with levels \"Low\", \"Med\", \"High\", how many dummy variables will `lm()` create automatically?",
    "options": [
      "1",
      "2 ($k-1$)",
      "3",
      "0"
    ],
    "answer": 1,
    "explanation": "**lm()**: Linear Model function in R.\n\nAnswer Key: 3 levels - 1 = 2 dummies",
    "id": 241,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "What does the `relevel()` function do?",
    "options": [
      "It removes outliers. methodology",
      "It changes the reference category...",
      "It centers a continuous variable.",
      "It runs a regression. methodology"
    ],
    "answer": 1,
    "explanation": "**cor() function**: Calculates correlation in R.",
    "id": 242,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Homoscedasticity means:",
    "options": [
      "The residuals are normally distributed.",
      "The variance of the residuals is constant...",
      "The predictor variables are uncorrelated.",
      "The relationship is linear. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Homoscedasticity**: Constant variance of residuals across X.",
    "id": 243,
    "module": "Module 6: More Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "In the multiple regression equation $Y = b_0 + b_1X_1 + b_2X_2 + \\dots$, $b_1$ is interpreted as:",
    "options": [
      "The correlation between Y and $X_1$. (in statistics)",
      "The predicted change in Y for a 1-unit increase in $X_1$,",
      "The predicted change in Y for a 1-unit increase in $X_1$, ignoring other predictors.",
      "The standardized effect size. (additional context"
    ],
    "answer": 1,
    "explanation": "**Regression Equation**: Y = b0 + b1*X + e. Intercept + Slope.",
    "id": 244,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Why do we prefer Adjusted $R^2$ over Multiple $R^2$ in multiple regression?",
    "options": [
      "Adjusted $R^2$ is always higher. (in statistics)",
      "Multiple $R^2$ increases with every predictor added,",
      "Adjusted $R^2$ is easier to calculate. methodology",
      "Multiple $R^2$ cannot be interpreted as variance explained."
    ],
    "answer": 1,
    "explanation": "**Multiple Regression**: Predicting Y from multiple Xs.",
    "id": 245,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Multicollinearity occurs when:",
    "options": [
      "The predictors are highly correlated with the outcome.",
      "The predictors are highly correlated with each other.",
      "The residuals are correlated with the fitted values.",
      "The sample size is too small."
    ],
    "answer": 1,
    "explanation": "**Multicollinearity**: High correlation between predictors. Bad.",
    "id": 246,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "A Variance Inflation Factor (VIF) value of 15 indicates:",
    "options": [
      "No collinearity.",
      "Moderate collinearity.",
      "Severe (high) multicollinearity.",
      "Perfect independence."
    ],
    "answer": 2,
    "explanation": "**VIF**: Variance Inflation Factor. > 10 is bad.",
    "id": 247,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Interpreting Output:\n**Which conclusion is supported?**",
    "options": [
      "Both predictors significantly predict the outcome.",
      "$X_1$ is a significant predictor, but $X_2$ is not...",
      "$X_2$ is a better predictor than $X_1$. approach",
      "The intercept is not significant. (in statistics)"
    ],
    "answer": 1,
    "explanation": "Evaluate the model comparison metrics (AIC, BIC, or ANOVA results).",
    "id": 248,
    "codeSnippet": "Coefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   10.0      2.0      5.00   <.001\nX1             3.0      0.5      6.00   <.001\nX2             0.1      0.5      0.20    0.84",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Which R function compares two nested models to see if adding variables significantly improves fit?",
    "options": [
      "`summary()`",
      "`anova(model1, model2)`",
      "`cor.test()`",
      "`plot()`"
    ],
    "answer": 1,
    "explanation": "**Nested Models**: One model is a subset of the other (e.g., dropped a term).",
    "id": 249,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "When comparing non-nested models or checking model fit penalizing for complexity, which metric is best?",
    "options": [
      "$SS_{Total}$ methodology",
      "AIC (Akaike Information...",
      "F-statistic. methodology",
      "Pearson's r. methodology"
    ],
    "answer": 1,
    "explanation": "**Nested Models**: One model is a subset of the other (e.g., dropped a term).",
    "id": 250,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Interpreting Output (Model Comparison):\n**What does this ANOVA table tell us?**",
    "options": [
      "Model 1 is significantly better than Model 2.",
      "Adding `airplay` (Model 2) significantly reduced the...",
      "There is no significant difference between the models.",
      "Model 2 explains less variance. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**anova(m1, m2)**: Performs LRT in R for nested models.",
    "id": 251,
    "codeSnippet": "Model 1: sales ~ adverts\nModel 2: sales ~ adverts + airplay",
    "codeOutput": "Res.Df    RSS Df Sum of Sq      F    Pr(>F)\n1    198 862264\n2    197 492362  1    369902  148.0  < 2.2e-16 ***",
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Stepwise regression (e.g., backward elimination) is criticized because:",
    "options": [
      "It relies on p-values/AIC rather than theory,",
      "It is computationally impossible in R.",
      "It always yields the worst $R^2$. methodology",
      "It cannot handle categorical variables."
    ],
    "answer": 0,
    "explanation": "**Regression Equation**: Y = b0 + b1*X + e. Intercept + Slope.",
    "id": 252,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "Which command in R runs a multiple regression with all predictors in the dataframe?",
    "options": [
      "`lm(y ~ ., data = df)`",
      "`lm(y ~ x, data = df)`",
      "`lm(y ~ 1, data = df)`",
      "`lm(y ~ all, data = df)`"
    ],
    "answer": 0,
    "explanation": "**Multiple Regression**: Predicting Y from multiple Xs.",
    "id": 253,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "In a standard Spider Plot (radar chart) for model performance, usually:",
    "options": [
      "Points further out indicate better...",
      "It only shows $R^2$. methodology",
      "It shows residuals. methodology",
      "It maps the linear relationship."
    ],
    "answer": 0,
    "explanation": "**Q-Q Plot**: Checks Normality of residuals.",
    "id": 254,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "If you add a predictor to a model and the $R^2$ goes up but the AIC also goes up (gets worse), this suggests:",
    "options": [
      "The new predictor is extremely important.",
      "The new predictor does not justify the...",
      "The calculation is wrong. (in statistics)",
      "The sample size is too large. methodology"
    ],
    "answer": 1,
    "explanation": "**AIC**: Akaike Information Criterion. Lower is better. Penalizes parameter count.",
    "id": 255,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "What is the degrees of freedom for the model ($df_{mod}$) in a multiple regression with 3 predictors ($K=3$)?",
    "options": [
      "$N - 1$",
      "3",
      "$N - 3 - 1$",
      "1"
    ],
    "answer": 1,
    "explanation": "**Degrees of Freedom**: df_residual = N - k - 1 (or N-2 for simple).",
    "id": 256,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "If two predictors are perfectly correlated ($r = 1.0$), the regression model:",
    "options": [
      "Will work perfectly. methodology",
      "Will fail to estimate unique coefficie...",
      "Will assign equal weights to both.",
      "Will have an $R^2$ of 0. approach"
    ],
    "answer": 1,
    "explanation": "**Regression Equation**: Y = b0 + b1*X + e. Intercept + Slope.",
    "id": 257,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "The \"Hierarchical Entry\" method in regression means:",
    "options": [
      "The computer decides the order. methodology",
      "You enter variables in blocks/steps based on...",
      "You enter all variables at once. approach",
      "You only interpret the highest p-value."
    ],
    "answer": 1,
    "explanation": "**Hierarchical Regression**: Adding blocks of predictors.",
    "id": 258,
    "module": "Module 7: Multiple Regression & Assumptions"
  },
  {
    "type": "mc",
    "question": "An interaction effect occurs when:",
    "options": [
      "Two predictors are highly correlated. methodology",
      "The effect of one predictor on the outcome depends...",
      "The effect of X on Y is mediated by M. methodology",
      "The relationship between X and Y is non-linear."
    ],
    "answer": 1,
    "explanation": "**Interaction Effect**: Effect of X1 depends on X2.",
    "id": 259,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "In the equation $Y = b_0 + b_1X + b_2Z + b_3(X \\times Z)$, what does $b_3$ represent?",
    "options": [
      "The main effect of X.",
      "The main effect of Z.",
      "The interaction effect (change...",
      "The intercept. methodology"
    ],
    "answer": 2,
    "explanation": "**Regression Equation**: Y = b0 + b1*X + e. Intercept + Slope.",
    "id": 260,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "How do you specify an interaction between `age` and `education` in an R formula?",
    "options": [
      "`age + education`",
      "`age * education` (or `age +...",
      "`age / education`",
      "`age - education`"
    ],
    "answer": 1,
    "explanation": "**SEM Formula**: SEM =  / N.",
    "id": 261,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Interpreting Output:\n**The interaction term is positive ($0.5$). This suggests that as social `support` increases:**",
    "options": [
      "The negative effect of `stress` on the outcome...",
      "The negative effect of `stress` becomes *stronger* (more negative).",
      "There is no effect of stress. (in statistics)",
      "Support decreases the outcome. (in statistics)"
    ],
    "answer": 0,
    "explanation": "**Interaction Term**: X1 * X2.\n\nAnswer Key: Slope of stress is -2. As support goes up, we add $0.5 \\times Support$ to the slope. $-2 + 0.5 = -1.5$, which is less negative.",
    "id": 262,
    "codeSnippet": "Coefficients:\n               Estimate Std. Error t value Pr(>|t|)\n(Intercept)        50.0      5.0     10.0   <.001\nstress             -2.0      0.5     -4.0   <.001\nsupport             3.0      0.5      6.0   <.001\nstress:support      0.5      0.1      5.0   <.001",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "When an interaction is significant, how should you interpret the \"main effects\" ($b_1, b_2$)?",
    "options": [
      "As global averages that apply to everyone.",
      "As conditional effects (simple slopes) when...",
      "They should be ignored completely.",
      "They are now standardized. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Significant t-test for Slope**: Predictor significantly predicts outcome.",
    "id": 263,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "What is a \"Simple Slopes Analysis\"?",
    "options": [
      "Running a regression with only one variable.",
      "Probing an interaction by examining the...",
      "Plotting the residuals. (in statistics)",
      "Calculating the simple mean. methodology"
    ],
    "answer": 1,
    "explanation": "**Simple Slopes**: Slope of X1 at specific levels of X2.",
    "id": 264,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "In R, which package is commonly used to probe and plot interactions (e.g., `sim_slopes` or `interact_plot`)?",
    "options": [
      "`interactions` or ...",
      "`gvlma` (in statistics)",
      "`MASS` (in statistics)",
      "`base` (in statistics)"
    ],
    "answer": 0,
    "explanation": "**Q-Q Plot**: Checks Normality of residuals.",
    "id": 265,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "If the lines in an interaction plot are parallel, it indicates:",
    "options": [
      "A strong interaction.",
      "No interaction.",
      "A crossover interaction.",
      "Multicollinearity."
    ],
    "answer": 1,
    "explanation": "**Q-Q Plot**: Checks Normality of residuals.",
    "id": 266,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Why is centering continuous predictors recommended when testing interactions?",
    "options": [
      "It turns the variables into categorical ones.",
      "It reduces multicollinearity between the...",
      "It increases the sample size. methodology",
      "It ensures normality. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**Centering**: Essential for raw polynomials to reduce multicollinearity.",
    "id": 267,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Interpreting Output (Visual):\n*(Imagine a plot where the slope of X on Y is positive for the \"High Z\" group, flat for \"Medium Z\", and negative for \"Low Z\".)*\n**This is an example of:**",
    "options": [
      "A spurious correlation.",
      "A crossover (disordinal) or sig...",
      "Homoscedasticity. methodology",
      "A main effect only. approach"
    ],
    "answer": 1,
    "explanation": "**Mad Men Example**: Correlation implies causation fallacy or 'Just Drunk' = Spurious/Chance.",
    "id": 268,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "To decompose an interaction involving a categorical variable (e.g., `Treatment` vs `Control`) and a continuous variable (`Dose`), you would look at:",
    "options": [
      "The slope of `Dose` for the Treatment...",
      "The mean of Dose. (in statistics)",
      "The correlation between Treatment and Control.",
      "The intercept only. (in statistics)"
    ],
    "answer": 0,
    "explanation": "**Distributions for Categorical Data**: Chi-square is often used for categorical/count data analysis.",
    "id": 269,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "The term for breaking down an interaction into its lower-order components is:",
    "options": [
      "Decompose.",
      "Standardize.",
      "Bootstrap.",
      "Inflate."
    ],
    "answer": 0,
    "explanation": "**Interaction Term**: X1 * X2.",
    "id": 270,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "If you have a significant interaction, do you need to keep the main effects in the model?",
    "options": [
      "No, remove them to save degrees of freedom.",
      "Yes, for hierarchical, marginality,",
      "Only if they are significant. methodology",
      "Only the intercept matters. methodology"
    ],
    "answer": 1,
    "explanation": "**summary(model)**: Shows coefficients, R2, F-test.",
    "id": 271,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Using the `emmeans` package helps you to:",
    "options": [
      "Calculate Estimated Marginal Means and",
      "Calculate the mean of the residuals.",
      "Run a stepwise regression. methodology",
      "Create dummy variables. methodology"
    ],
    "answer": 0,
    "explanation": "**emmeans**: Package for simple slopes/marginal means.",
    "id": 272,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "\"Johnson-Neyman\" intervals are used to:",
    "options": [
      "Find the specific range of...",
      "Detect outliers. approach",
      "Calculate VIF. methodology",
      "Normalize the data."
    ],
    "answer": 0,
    "explanation": "**Johnson-Neyman**: Finds regions of significance for moderator.",
    "id": 273,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Which R code creates a centered variable `age_c`?",
    "options": [
      "`df$age_c <- df$age - mean(df$age)`",
      "`df$age_c <- mean(df$age)`",
      "`df$age_c <- scale(df$age)` (Note: `scale` standardizes by default, not just centering).",
      "`df$age_c <- df$age / sd(df$age)`"
    ],
    "answer": 0,
    "explanation": "**Centering**: Helps reduce multicollinearity for interaction terms.",
    "id": 274,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "`confint(model)` in R provides:",
    "options": [
      "The confidence intervals for the predicted values.",
      "The confidence intervals for the regression...",
      "The correlation matrix. (in statistics)",
      "The R-squared value. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**summary(model)**: Shows coefficients, R2, F-test.",
    "id": 275,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "When reporting multiple regression results, which statistics are essential?",
    "options": [
      "$b$ (or $\\beta$), SE, t, p,",
      "Only the p-values.",
      "Only the $R^2$. methodology",
      "The raw data frame."
    ],
    "answer": 0,
    "explanation": "**Multiple Regression**: Predicting Y from multiple Xs.",
    "id": 276,
    "module": "Module 8: Interactions"
  },
  {
    "type": "tf",
    "question": "True or False: Correlation implies Causation.",
    "options": [
      "True",
      "False"
    ],
    "answer": 1,
    "explanation": "**Correlation vs Causation**: Correlation does NOT imply causation.",
    "id": 277,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Which plot is used to detect outliers based on leverage and residuals?",
    "options": [
      "Residuals vs Leverage (Cook's dis...",
      "Histogram of outcome. approach",
      "Boxplot of predictors.",
      "Scatterplot of X vs Y."
    ],
    "answer": 0,
    "explanation": "**Residual**: Observed Y - Predicted Y.",
    "id": 278,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "If `lm()` output shows `NA` for a coefficient, it usually means:",
    "options": [
      "The variable had no effect. approach",
      "Perfect multicollinearity (singularity)...",
      "The variable is categorical.",
      "The sample size is too big. approach"
    ],
    "answer": 1,
    "explanation": "**lm()**: Linear Model function in R.",
    "id": 279,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Interpreting `summary()`:** The bottom line says `F-statistic: 50 on 2 and 97 DF, p-value: < 2.2e-16`.\n**What does the `2 and 97 DF` refer to?**",
    "options": [
      "2 predictors ($df_{mod}$) and 97...",
      "2 observations and 97 variables.",
      "2 models compared. (in statistics)",
      "An error in calculation. approach"
    ],
    "answer": 0,
    "explanation": "**F-statistic**: Tests if whole model is better than null model.",
    "id": 280,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "How do you interpret a standardized intercept?",
    "options": [
      "The value of Y when all predictor...",
      "It is always 0. (in statistics)",
      "It represents the correlation.",
      "It is the mean of Y. approach"
    ],
    "answer": 0,
    "explanation": "**Intercept (b0)**: Predicted Y when X = 0.",
    "id": 281,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "In `ggplot2`, adding a regression line to a scatterplot is done with:",
    "options": [
      "`geom_smooth(method = \"lm\")`",
      "`geom_line()`",
      "`geom_bar()`",
      "`geom_boxplot()`"
    ],
    "answer": 0,
    "explanation": "**Scatterplot**: Best plot to visualize correlation.",
    "id": 282,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "A researcher reports: \"$b = 0.5, t(100) = 1.5, p = .14$\". What is the conclusion?",
    "options": [
      "The effect is significant. methodology",
      "The effect is not statistically signific...",
      "The sample size is too small.",
      "There is a strong relationship."
    ],
    "answer": 1,
    "explanation": "**Reporting Results**: b, SE, t, p, R2.",
    "id": 283,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "If you run a regression and the residuals are not normally distributed, what might you consider?",
    "options": [
      "Bootstrapping or transforming the dependent...",
      "Using a t-test instead. (in statistics)",
      "Ignoring it; regression is robust.",
      "Increasing the number of predictors."
    ],
    "answer": 0,
    "explanation": "**Residual**: Observed Y - Predicted Y.",
    "id": 284,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Which of the following is a measure of effect size in regression?",
    "options": [
      "p-value (in statistics)",
      "$f^2$ (Cohen's $f^2$) or",
      "Degrees of freedom.",
      "The intercept. approach"
    ],
    "answer": 1,
    "explanation": "**Effect Size r**: 0.1 small, 0.3 medium, 0.5 large.",
    "id": 285,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Parsimony in model building means:",
    "options": [
      "Adding as many variables as possible.",
      "Choosing the simplest model that explains...",
      "Maximizing $R^2$ at all costs. approach",
      "Using complex interactions. methodology"
    ],
    "answer": 1,
    "explanation": "**Parsimony**: Simpler model is better (if fit is similar).",
    "id": 286,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "If you calculate `AIC` for Model A = 200 and Model B = 195, which model is preferred?",
    "options": [
      "Model A",
      "Model B",
      "Neither",
      "They are equivalent."
    ],
    "answer": 1,
    "explanation": "**AIC**: Akaike Information Criterion. Lower is better. Penalizes parameter count.",
    "id": 287,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Interpreting Output:\n**Is multicollinearity a problem here?**",
    "options": [
      "Yes, values are \\> 1.",
      "No, values are well below 5 or 10.",
      "Yes, because they are not equal.",
      "Cannot tell."
    ],
    "answer": 1,
    "explanation": "**Multicollinearity**: High correlation between predictors. Bad.",
    "id": 288,
    "codeSnippet": "> vif(model)",
    "codeOutput": "age    income\n1.02345   1.05432",
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "To visualize a 3D regression plane (2 predictors, 1 outcome) in R, which packages were mentioned/useful?",
    "options": [
      "`scatterplot3d` or ...",
      "`dplyr` (in statistics)",
      "`tidyr` (in statistics)",
      "`stringr` methodology"
    ],
    "answer": 0,
    "explanation": "**Regression Equation**: Y = b0 + b1*X + e. Intercept + Slope.",
    "id": 289,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "If you want to predict an outcome Y based on Group (A, B, C), and \"A\" is the reference, the coefficient for \"B\" represents:",
    "options": [
      "The mean of group B. methodology",
      "The difference between mean of B and",
      "The difference between B and C.",
      "The average of all groups."
    ],
    "answer": 1,
    "explanation": "**Reference Group**: The group coded 0 on all dummies.",
    "id": 290,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "What is the range of values for $R^2$?",
    "options": [
      "$-\\infty$ to $+\\infty$",
      "-1 to 1",
      "0 to 1",
      "0 to 100"
    ],
    "answer": 2,
    "explanation": "**Probability Range**: Probabilities are always between 0 and 1.",
    "id": 291,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "What is the correct syntax to extract coefficients from a saved model object `fit`?",
    "options": [
      "`fit$coefficients` or `coe...",
      "`fit$residuals`",
      "`fit$r.squared`",
      "`fit$p.value` approach"
    ],
    "answer": 0,
    "explanation": "**summary(model)**: Shows coefficients, R2, F-test.",
    "id": 292,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "A \"suppressor variable\" in multiple regression is one that:",
    "options": [
      "Has no correlation with the...",
      "Decreases the $R^2$.",
      "Is an outlier. methodology",
      "Violates assumptions."
    ],
    "answer": 0,
    "explanation": "**Multiple Regression**: Predicting Y from multiple Xs.",
    "id": 293,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "If you have 5 predictors and $N=20$, you likely have:",
    "options": [
      "High statistical power.",
      "Overfitting / poor power (rule...",
      "A perfect model. methodology",
      "Multicollinearity. approach"
    ],
    "answer": 1,
    "explanation": "**Adding Predictors**: R-squared always increases (or stays same). Adjusted R-squared might drop.",
    "id": 294,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "In a report, you write: \"$F(2, 147) = 4.56, p = .012$\". What does the \"2\" represent?",
    "options": [
      "Sample size. methodology",
      "Regression degrees of freedom...",
      "Residual degrees of freedom.",
      "The intercept. methodology"
    ],
    "answer": 1,
    "explanation": "The first number in F(df1, df2) represents the degrees of freedom for the model (predictors).",
    "id": 295,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "To compare the relative importance of predictors in a model, you should look at:",
    "options": [
      "Unstandardized $b$ coefficients.",
      "Standardized $\\beta$ coefficients.",
      "The p-values only.",
      "The standard errors."
    ],
    "answer": 1,
    "explanation": "**summary(model)**: Shows coefficients, R2, F-test.",
    "id": 296,
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "If you perform a `log` transformation on Y, the relationship being modeled changes from linear to:",
    "options": [
      "Quadratic.",
      "Exponential/Multiplicative.",
      "Logistic.",
      "Cubic.",
      "Price decreases sales, Quality increases sales, and high Quality *buffers* (reduces) the negative effect of Price on Sales (because the interaction is positive).",
      "Price decreases sales, but Quality has no effect.",
      "The interaction is not significant ($p > .05$).",
      "Price increases sales when Quality is 0."
    ],
    "answer": 1,
    "explanation": "**Linear Term Interpretation**: Slope at the mean of X (if orthogonal) or at X=0 (if raw).",
    "id": 297,
    "codeSnippet": "Call:\nlm(formula = sales ~ price * quality, data = products)",
    "codeOutput": "Coefficients:\nEstimate Std. Error t value Pr(>|t|)\n(Intercept)    50.00       5.00    10.00   <2e-16 ***\nprice          -2.00       0.50    -4.00   1e-04 ***\nquality         5.00       1.00     5.00   2e-05 ***\nprice:quality   0.20       0.10     2.00   0.048 *",
    "module": "Module 8: Interactions"
  },
  {
    "type": "mc",
    "question": "Question: You hypothesize that the relationship between \"Hours of Sleep\" and \"Cognitive Performance\" follows an inverted U-shape (performance increases with sleep up to a point, then decreases). Which polynomial term must be included in your regression model to test this specific shape?",
    "options": [
      "First-order (Linear) only",
      "Second-order (Quadratic)",
      "Third-order (Cubic)",
      "Fourth-order (Quartic)"
    ],
    "answer": 1,
    "explanation": "An inverted U-shape is modeled with a negative quadratic term.",
    "id": 298,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: A cubic polynomial function ($y = ax^3 + bx^2 + cx + d$) allows for how many points of inflection in the regression line?",
    "options": [
      "0",
      "1",
      "2",
      "3"
    ],
    "answer": 2,
    "explanation": "A cubic polynomial has degree 3, allowing for up to 2 inflection points.",
    "id": 299,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: When including a quadratic term (`I(x^2)`) in a linear model in R, what other term *must* generally be included for the model coefficients to be chemically/mathematically interpretable?",
    "options": [
      "The cubic term (`I(x^3)`)",
      "The lower-order linear term (`x`)",
      "An interaction term",
      "A random intercept"
    ],
    "answer": 1,
    "explanation": "When including a higher-order term like x^2, the lower-order term x must be included to maintain hierarchical structure.",
    "id": 300,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nBased on the sign of the quadratic term (`I(chocolate^2)`), how would you describe the shape of the relationship?",
    "options": [
      "U-shaped (Convex; happiness decreases then increases)",
      "Inverted U-shaped (Concave; happiness...",
      "Linear positive (in statistics)",
      "Linear negative (in statistics)"
    ],
    "answer": 1,
    "explanation": "Negative quadratic coefficient indicates a downward-opening curve).",
    "id": 301,
    "codeSnippet": "Call:\nlm(formula = happiness ~ chocolate + I(chocolate^2), data = diet_data)",
    "codeOutput": "Coefficients:\n(Intercept)      chocolate  I(chocolate^2)\n10.50           2.30           -0.15",
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: In the output from the previous question, if the coefficient for `I(chocolate^2)` were **positive** (e.g., +0.15), what would the curve look like?",
    "options": [
      "It opens downward (Inverted U).",
      "It opens upward (U-shaped).",
      "An S-curve.",
      "A straight line."
    ],
    "answer": 1,
    "explanation": "A positive quadratic coefficient results in a U-shaped (convex) curve.",
    "id": 302,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "tf",
    "question": "Question:** **[Mock R Output]\nTrue or False: The quadratic trend is statistically significant at the $\\alpha = 0.05$ level.",
    "options": [
      "True",
      "False"
    ],
    "answer": 0,
    "explanation": "p-value 0.015 \\< 0.05).",
    "id": 303,
    "codeSnippet": "Coefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)      50.00     5.00    10.00  < 2e-16 ***\nTime              5.00     1.00     5.00  1.2e-05 ***\nI(Time^2)         0.50     0.20     2.50   0.015 *",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: What is a primary statistical issue often encountered when adding raw polynomial terms (e.g., $x$, $x^2$, $x^3$) to a regression model?",
    "options": [
      "Heteroscedasticity approach",
      "Multicollinearity (high correla...",
      "Non-normality of residuals",
      "Autocorrelation methodology"
    ],
    "answer": 1,
    "explanation": "Raw polynomials are highly correlated with each other, causing multicollinearity.",
    "id": 304,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: Which R function creates **orthogonal polynomials** to reduce multicollinearity between polynomial terms?",
    "options": [
      "`ortho()`",
      "`I()`",
      "`poly()`",
      "`scale()`"
    ],
    "answer": 2,
    "explanation": "The poly() function generates orthogonal polynomials by default.",
    "id": 305,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "tf",
    "question": "Question: True or False: Using orthogonal polynomials (e.g., `poly(x, 2)`) changes the overall fit ($R^2$) of the model compared to using raw polynomials (`x + I(x^2)`).",
    "options": [
      "True",
      "False"
    ],
    "answer": 1,
    "explanation": "The overall fit remains the same; only the coefficients and their correlations change).",
    "id": 306,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nIf you used raw polynomials instead of `poly(x, 2)`, which value in this output would definitively remain the exact same?",
    "options": [
      "The estimate for `poly(x, 2)1`",
      "The estimate for `poly(x, 2)2`",
      "The t-value for the intercept approach",
      "The $R^2$ of the model (not shown,"
    ],
    "answer": 3,
    "explanation": "Coefficients change, but the variance explained ($R^2$) and overall model fit do not).",
    "id": 307,
    "codeSnippet": "Call: lm(formula = y ~ poly(x, 2), data = df)\n...\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)  20.00     0.50     40.00  <2e-16\npoly(x, 2)1   5.00     1.00      5.00  <2e-16\npoly(x, 2)2  -3.00     1.00     -3.00   0.004",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: You run a linear model (`m1`) and a quadratic model (`m2`). You compare them using `anova(m1, m2)`.\n**[Mock R Output]**\nWhich model should you choose based on this output?",
    "options": [
      "Model 1 (Linear)",
      "Model 2 (Quadratic)",
      "Neither fits well",
      "Not enough information"
    ],
    "answer": 1,
    "explanation": "The reduction in RSS is significant, p \\< .001).",
    "id": 308,
    "codeSnippet": "Model 1: y ~ x\nModel 2: y ~ x + I(x^2)\nRes.Df    RSS Df Sum of Sq      F    Pr(>F)\n1     98 1500.0\n2     97 1200.0  1     300.0  24.25 3.5e-06 ***",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: If the p-value in the ANOVA table comparing a linear and quadratic model was **0.35**, what would you conclude?",
    "options": [
      "The quadratic term significantly improves model fit.",
      "The quadratic term does not significantly improve...",
      "The linear term is not significant. methodology",
      "You should try a cubic model. (in statistics)"
    ],
    "answer": 1,
    "explanation": "**anova(m1, m2)**: Performs LRT in R for nested models.",
    "id": 309,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: \"Empirically\" deciding to use polynomial regression usually involves inspecting which plot for curve-like patterns?",
    "options": [
      "Histogram of the outcome",
      "Residuals vs. Fitted values plot",
      "Boxplot of the predictor",
      "Correlation matrix"
    ],
    "answer": 1,
    "explanation": "Residuals vs. Fitted values plots reveal non-linear patterns if a polynomial term is needed.",
    "id": 310,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: Which is **NOT** a valid reason/use case for polynomial regression?",
    "options": [
      "Theoretical prediction of a curve (e.g., Yerkes-Dodson).",
      "Residual plots show a non-linear pattern. (in statistics)",
      "To extrapolate predictions far outside the observed range of...",
      "To account for non-linear trends within the range of your data."
    ],
    "answer": 2,
    "explanation": "Polynomials are notoriously bad at extrapolating outside observed data).",
    "id": 311,
    "module": "Module 10: Multiple Regression with Polynomials"
  },
  {
    "type": "mc",
    "question": "Question: In a mixed model, what distinguishes a **fixed effect** from a **random effect**?",
    "options": [
      "Fixed effects vary by subject; random effects are constant. (in statistics)",
      "Fixed effects estimate population-level parameters; random effects estimate...",
      "Fixed effects are for categorical variables; random effects are for continuous variables.",
      "Fixed effects are optional; random effects are mandatory. (in statistics)"
    ],
    "answer": 1,
    "explanation": "Fixed effects estimate population means; random effects estimate subject-specific deviations.",
    "id": 312,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: Which of the following is a classic example of a variable often treated as a **random effect** in a Repeated Measures design?",
    "options": [
      "Treatment condition (Control vs. Experimental)",
      "Participant/Subject ID",
      "Age of participant",
      "Gender"
    ],
    "answer": 1,
    "explanation": "**Mad Men Example**: Correlation implies causation fallacy or 'Just Drunk' = Spurious/Chance.",
    "id": 313,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: Why do we use Mixed Models instead of standard Multiple Regression for nested data?",
    "options": [
      "To violate the assumption of linearity. methodology",
      "To account for non-independence of observations (cluster...",
      "To calculate easier p-values. (in statistics)",
      "Because standard regression cannot handle continuous predictors."
    ],
    "answer": 1,
    "explanation": "Mixed models account for the correlation of residuals within groups/subjects.",
    "id": 314,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: Which R package is primarily used for running linear mixed-effects models (`lmer`)?",
    "options": [
      "`ggplot2`",
      "`dplyr`",
      "`lme4`",
      "`stats`"
    ],
    "answer": 2,
    "explanation": "lme4 is the standard package for linear mixed-effects models in R.",
    "id": 315,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: What is the correct syntax for a random intercept for `Subject` in an `lmer` formula?",
    "options": [
      "`(Subject | 1)`",
      "`(1 | Subject)`",
      "`random = Subject`",
      "`(1 + Subject)`"
    ],
    "answer": 1,
    "explanation": "The pipe | separates the random term from the grouping variable.",
    "id": 316,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: How would you specify a model with a fixed effect for `Condition`, a random intercept for `Subject`, AND a random slope for `Condition` by `Subject`?",
    "options": [
      "`y ~ Condition + (1 | Subject)`",
      "`y ~ Condition + (Condition | Subject)`",
      "`y ~ Condition + (1 | Subject) + (1 | Condition)`",
      "`y ~ Condition + (0 | Subject)`"
    ],
    "answer": 1,
    "explanation": "Note: `(Condition | Subject)` implicitly includes the intercept `1 + Condition`).",
    "id": 317,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: What does the term `(1 | School/Class)` imply in a mixed model formula?",
    "options": [
      "Random intercepts for School only.",
      "Random intercepts for Class only.",
      "Nested random effects: Classes nested within Schools.",
      "Crossed random effects between School and Class."
    ],
    "answer": 2,
    "explanation": "The slash / denotes nesting: Classes within Schools.",
    "id": 318,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nCalculate the Intraclass Correlation Coefficient (ICC).",
    "options": [
      "0.20",
      "0.80",
      "4.00",
      "0.25"
    ],
    "answer": 1,
    "explanation": "Calculation: $\\frac{400}{400 + 100} = 0.80$).",
    "id": 319,
    "codeSnippet": "Random effects:\nGroups   Name        Variance Std.Dev.\nSubject  (Intercept) 400.0    20.0\nResidual             100.0    10.0\nNumber of obs: 200, groups:  Subject, 20",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: What does an ICC of 0.80 (from the previous question) indicate?",
    "options": [
      "80% of the variance in the outcome is due to differences...",
      "80% of the variance is due to measurement error (residual).",
      "The subjects are not correlated. (in statistics)",
      "You should definitely use a simple linear regression."
    ],
    "answer": 0,
    "explanation": "ICC is the proportion of total variance explained by the grouping structure (between-group variance).",
    "id": 320,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nWhat is the predicted value of the outcome for `Day = 0` (the intercept) for the *average* subject (ignoring random deviations)?",
    "options": [
      "10.00",
      "250.00",
      "260.00",
      "25.00"
    ],
    "answer": 1,
    "explanation": "The Intercept (250.00) represents the value when Day=0.",
    "id": 321,
    "codeSnippet": "Fixed effects:\n            Estimate Std. Error t value\n(Intercept)  250.00    10.00     25.00\nDay           10.00     2.00      5.00",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: In the output above (\\#24), what is the estimated change in the outcome for every 1-unit increase in Day?",
    "options": [
      "250.00",
      "25.00",
      "10.00",
      "2.00"
    ],
    "answer": 2,
    "explanation": "The slope for Day (10.00) represents the change per unit of time.",
    "id": 322,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nWhat does the correlation of -0.50 tell you?",
    "options": [
      "Subjects with higher baseline intercepts tend to have steeper positive slopes.",
      "Subjects with higher baseline intercepts tend to have...",
      "The model did not converge. (additional context) (",
      "Day is negatively correlated with the outcome. methodology"
    ],
    "answer": 1,
    "explanation": "Negative correlation between Intercept and Slope).",
    "id": 323,
    "codeSnippet": "Random effects:\nGroups   Name        Variance Std.Dev. Corr\nSubject  (Intercept) 500.0    22.36\nDay          50.0     7.07    -0.50",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: Ideally, if you add a fixed predictor to a mixed model that explains a lot of variance in the outcome, what should happen to the **Random Intercept Variance** (compared to the empty/null model)?",
    "options": [
      "It should increase. (in statistics)",
      "It should stay exactly the same.",
      "It should decrease (variance is \"expl...",
      "It should become negative."
    ],
    "answer": 2,
    "explanation": "Adding a significant predictor explains variance, reducing the unexplained random variance.",
    "id": 324,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: Which estimation method is generally preferred when comparing nested mixed models with **different fixed effects** using a Likelihood Ratio Test?",
    "options": [
      "REML (Restricted Maximum Likelihood)",
      "ML (Maximum Likelihood)",
      "OLS (Ordinary Least Squares)",
      "T-test"
    ],
    "answer": 1,
    "explanation": "REML is better for final parameter estimates, ML for comparing fixed effects).",
    "id": 325,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: If you see the warning \"Singular fit\" in R output for an `lmer` model, what does it usually mean?",
    "options": [
      "The model fits the data perfectly (R^2 = 1).",
      "The random effects structure is too complex...",
      "You have too many outliers. (in statistics)",
      "You should add more random slopes. approach"
    ],
    "answer": 1,
    "explanation": "Singular fit means the model is overparameterized, often with random variance near zero.",
    "id": 326,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: What is $R^2_{marginal}$ in the context of mixed models?",
    "options": [
      "Variance explained by the entire model (fixed + random).",
      "Variance explained by the fixed effects only.",
      "Variance explained by the random effects only.",
      "The error variance."
    ],
    "answer": 1,
    "explanation": "Marginal R-squared includes variance explained by fixed effects only.",
    "id": 327,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: What is $R^2_{conditional}$?",
    "options": [
      "Variance explained by the fixed effects only.",
      "Variance explained by the entire model (fixed +...",
      "The p-value of the model. (in statistics)",
      "The correlation between random slopes and intercepts."
    ],
    "answer": 1,
    "explanation": "Conditional R-squared includes variance explained by both fixed and random effects.",
    "id": 328,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output - Model Comparison]\nWhich model is preferred based on this output?",
    "options": [
      "mod1 (fewer degrees of freedom).",
      "mod1 (higher AIC). (in statistics)",
      "mod2 (lower AIC and significant Likelihood...",
      "Neither, they are statistically equivalent."
    ],
    "answer": 2,
    "explanation": "Mod2 has a lower AIC and a significant LRT result, indicating better fit.",
    "id": 329,
    "codeSnippet": "Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)\nmod1   4 1200.0 1220.0 -596.0   1192.0\nmod2   5 1150.0 1175.0 -570.0   1140.0  52.0      1  5e-13 ***",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: Why do we typically use the `lmerTest` package in addition to `lme4`?",
    "options": [
      "To make better plots. approach",
      "To get p-values for the fixed effe...",
      "To run Bayesian models.",
      "To handle missing data."
    ],
    "answer": 1,
    "explanation": "lmerTest extends lme4 to provide p-values for t-tests.",
    "id": 330,
    "module": "Module 11: Mixed Models"
  },
  {
    "type": "mc",
    "question": "Question: A Growth Curve Model (GCM) is essentially a special case of which type of model?",
    "options": [
      "ANOVA (in statistics)",
      "Mixed-Effects Model (Mult...",
      "Chi-Square Test",
      "Logistic Regression"
    ],
    "answer": 1,
    "explanation": "Growth Curve Models are Multilevel Models applied to longitudinal data.",
    "id": 331,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: What is the defining feature of the data required for Growth Curve Modeling?",
    "options": [
      "It must be categorical. (in statistics)",
      "It must be cross-sectional (one time point).",
      "It must be longitudinal (repeated measures...",
      "It must have no missing values. approach"
    ],
    "answer": 2,
    "explanation": "Growth models require repeated measures (longitudinal data).",
    "id": 332,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: In an **Unconditional Growth Model**, what is typically the only fixed predictor included?",
    "options": [
      "Treatment Group",
      "Time",
      "Gender",
      "Nothing (only the intercept)"
    ],
    "answer": 1,
    "explanation": "Unconditional growth models include Time to model the trajectory but no other predictors.",
    "id": 333,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: What does a \"Conditional\" Growth Model include that an Unconditional one does not?",
    "options": [
      "Random intercepts.",
      "A time variable.",
      "Covariates or predictors of...",
      "Error terms. methodology"
    ],
    "answer": 2,
    "explanation": "Conditional models includes predictors (covariates) to explain variability in intercepts or slopes.",
    "id": 334,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: If you want to model a non-linear trajectory over time in a GCM, what do you usually add?",
    "options": [
      "More subjects. methodology",
      "Polynomial terms for Time (e...",
      "More random effects.",
      "A control group. approach"
    ],
    "answer": 1,
    "explanation": "Polynomial terms like Time^2 allow for modeling non-linear curves.",
    "id": 335,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nThe reference group is Group A. What is the slope (rate of growth) for **Group A**?",
    "options": [
      "100.00",
      "5.00",
      "3.00",
      "-2.00"
    ],
    "answer": 1,
    "explanation": "The main effect of Time represents the slope for the reference group).",
    "id": 336,
    "codeSnippet": "Fixed effects:\n            Estimate Std. Error t value\n(Intercept)  100.00     2.00     50.00\nTime           5.00     0.50     10.00\nGroupB        10.00     3.00      3.33\nTime:GroupB   -2.00     0.70     -2.85",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: Using the output from Question \\#39, what is the slope (rate of growth) for **Group B**?",
    "options": [
      "5.00",
      "10.00",
      "3.00 (5.00 - 2.00)",
      "7.00 (10.00 - 3.00)"
    ],
    "answer": 2,
    "explanation": "Slope A + Interaction term = 5.00 + (-2.00) = 3.00).",
    "id": 337,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: Using the output from Question \\#39, how do the intercepts differ between Group A and Group B?",
    "options": [
      "They don't differ. (in statistics)",
      "Group B starts 10.00 units higher than...",
      "Group B starts 2.00 units lower.",
      "Group B starts 5.00 units higher."
    ],
    "answer": 1,
    "explanation": "The main effect of GroupB represents the difference at Time=0).",
    "id": 338,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nHow would you describe the average growth trajectory based on these fixed effects?",
    "options": [
      "Linear increase forever. methodology",
      "Increases initially, but the rate of...",
      "Decreases initially, then increases (U-shape).",
      "Flat line. in data analysis"
    ],
    "answer": 1,
    "explanation": "Positive linear term, negative quadratic term).",
    "id": 339,
    "codeSnippet": "Formula: score ~ Time + I(Time^2) + (1 + Time | Subject)\nFixed effects:\n(Intercept)   50.0\nTime          10.0\nI(Time^2)     -1.5",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: In the model `score ~ Time + (Time | Subject)`, what does the random effect `(Time | Subject)` allow for?",
    "options": [
      "Each subject to have their own starting point (intercept) ONLY.",
      "Each subject to have their own starting point AND their own...",
      "Each subject to have their own rate of change ONLY (intercept is fixed).",
      "Time to vary randomly. (additional context) (additio"
    ],
    "answer": 1,
    "explanation": "The random slope (Time | Subject) allows the effect of Time (rate of change) to vary across subjects.",
    "id": 340,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: Why might you center the `Time` variable (e.g., set the start to 0) in a Growth Curve Model?",
    "options": [
      "To make the intercept interpretable as...",
      "To eliminate random effects. approach",
      "It is required by the `lmer` function.",
      "To increase the p-value. methodology"
    ],
    "answer": 0,
    "explanation": "Centering Time at 0 makes the intercept represent the status at the start of the study.",
    "id": 341,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nIf the variance for `Time` were 0, what would that imply?",
    "options": [
      "Everyone starts at the same score.",
      "Everyone changes at the exact same rate...",
      "There is no measurement error.",
      "The model is invalid. (in statistics)"
    ],
    "answer": 1,
    "explanation": "Zero variance in Time means all subjects change at the exact same rate.",
    "id": 342,
    "codeSnippet": "Random effects:\nGroups   Name        Variance\nSubject  (Intercept) 200.0\nTime         20.0",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "tf",
    "question": "Question: True or False: In a Growth Curve Model, the \"Random Intercept\" represents the variance in baseline performance across participants (assuming Time=0 is baseline).",
    "options": [
      "True",
      "False"
    ],
    "answer": 0,
    "explanation": "True. The random intercept captures individual differences in the starting value.",
    "id": 343,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: What is the \"maximal\" random effects structure usually recommended for GCM (if it converges)?",
    "options": [
      "Random intercepts only.",
      "Random intercepts and random slo...",
      "No random effects. approach",
      "Random slopes only. approach"
    ],
    "answer": 1,
    "explanation": "Maximal structure includes random intercepts and random slopes for all within-subject factors.",
    "id": 344,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: If your maximal model fails to converge, what is a common pragmatic next step?",
    "options": [
      "Give up and use ANOVA. approach",
      "Simplify the random effects (e.g.,",
      "Add more fixed effects. approach",
      "Increase the alpha level."
    ],
    "answer": 1,
    "explanation": "Simplifying the random effects structure is the standard approach to resolve convergence issues.",
    "id": 345,
    "module": "Module 12: Growth Curve Modeling"
  },
  {
    "type": "mc",
    "question": "Question: You want to compare the mean happiness scores of 3 different groups (A, B, C) and do not have repeated measures. Which linear model is equivalent to a One-Way ANOVA?",
    "options": [
      "`lm(happiness ~ 1)`",
      "`lm(happiness ~ group)`",
      "`lm(happiness ~ group + age)`",
      "`lmer(happiness ~ (1|group))`"
    ],
    "answer": 1,
    "explanation": "One-Way ANOVA is mathematically equivalent to a linear model with a categorical predictor.",
    "id": 346,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: You have data on students nested within classrooms. You want to predict test scores based on study time. Which model is most appropriate?",
    "options": [
      "Simple Linear Regression (`lm`)",
      "Multiple Regression (`lm` with dummies)",
      "Mixed-Effects Model (`lmer`) with random...",
      "Chi-square test. (in statistics)"
    ],
    "answer": 2,
    "explanation": "Mixed models properly account for the nesting of students within classrooms.",
    "id": 347,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: You want to test if the relationship between Stress and Performance is curvilinear (U-shaped). What do you use?",
    "options": [
      "Interaction term.",
      "Polynomial regression (q...",
      "T-test. (in statistics)",
      "Random slopes. approach"
    ],
    "answer": 1,
    "explanation": "A U-shape is a quadratic relationship, requiring a polynomial term.",
    "id": 348,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: You measured reaction time for the same subjects at 4 different time points. You want to see if reaction time decreases over time.",
    "options": [
      "Independent samples t-test.",
      "Growth Curve Model (Mixed Model...",
      "Pearson Correlation. approach",
      "One-way ANOVA. (in statistics)"
    ],
    "answer": 1,
    "explanation": "Repeated measures over time call for a Growth Curve Model.",
    "id": 349,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: Which statistic is best for comparing non-nested models (e.g., models with different dependent variables)?",
    "options": [
      "AIC (in statistics)",
      "ANOVA (Likelihood Ratio Test)",
      "You cannot directly compa...",
      "R-squared methodology"
    ],
    "answer": 2,
    "explanation": "Fit indices like AIC require the same outcome data).",
    "id": 350,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: What is the \"Null Ritual\"?",
    "options": [
      "A statistical test for zero variance.",
      "The mindless checking of p \\< 0.05 without...",
      "A method for handling missing data.",
      "Setting all intercepts to null. methodology"
    ],
    "answer": 1,
    "explanation": "**Null Hypothesis (H0)**: Assumption of No Effect, No Difference, or r = 0.",
    "id": 351,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "tf",
    "question": "Question: True or False: A p-value of 0.001 means the effect size is very large.",
    "options": [
      "True",
      "False"
    ],
    "answer": 1,
    "explanation": "It means the result is unlikely under the null; tiny effects can have tiny p-values in large samples).",
    "id": 352,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nWhat percent of the variance in the outcome is explained by the predictors?",
    "options": [
      "5.2%",
      "42%",
      "45%",
      "62%"
    ],
    "answer": 2,
    "explanation": "Multiple R-squared).",
    "id": 353,
    "codeSnippet": "> summary(model)",
    "codeOutput": "...\nResidual standard error: 5.2 on 48 degrees of freedom\nMultiple R-squared:  0.45,\tAdjusted R-squared:  0.42\nF-statistic: 19.6 on 2 and 48 DF,  p-value: 6.2e-07",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: In the output above (\\#56), is the overall model statistically significant?",
    "options": [
      "Yes, p \\< 0.05.",
      "No, p \\> 0.05.",
      "Cannot tell."
    ],
    "answer": 0,
    "explanation": "p-value 6.2e-07 is 0.00000062).",
    "id": 354,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nDoes this result suggest a violation of the normality assumption?",
    "options": [
      "Yes, because p \\> 0.05. (in statistics)",
      "Yes, because W is not 1. (in statistics)",
      "No, because p \\> 0.05, we fail to reject...",
      "No, Shapiro-Wilk is for homogeneity of variance."
    ],
    "answer": 2,
    "explanation": "A p-value > 0.05 indicates we do not reject the null hypothesis of normality.",
    "id": 355,
    "codeSnippet": "shapiro.test(residuals(model))\nW = 0.98, p-value = 0.65",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nIs there a multicollinearity problem here?",
    "options": [
      "No, all values are below 10. approach",
      "Yes, x3 has a VIF of 8.5, which is notabl...",
      "Yes, x1 is too low. (in statistics)",
      "VIF measures outliers, not collinearity."
    ],
    "answer": 1,
    "explanation": "VIF > 5 or 10 indicates potential multicollinearity issues.",
    "id": 356,
    "codeSnippet": "vif(model)\nx1    x2    x3\n1.2   1.1   8.5",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: A researcher finds that `Income` predicts `Happiness` linearly. However, they suspect that for very high incomes, happiness levels off (asymptotic). Which model limitation does polynomial regression (e.g., quadratic) share with linear regression regarding this specific \"leveling off\" theory?",
    "options": [
      "It cannot model curves. approach",
      "Polynomials tend to curve back down or",
      "It assumes equal variance."
    ],
    "answer": 1,
    "explanation": "Polynomials tend to curve back down or shoot up at the tails rather than truly plateauing (asymptotic).",
    "id": 357,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: You are analyzing data on chick weights over time (Growth Curve). You add `Diet` as a fixed effect. This turns your \"Unconditional Growth Model\" into a...?",
    "options": [
      "Conditional Growth Model.",
      "Random Intercept Model.",
      "Null Model.",
      "Logistic Model."
    ],
    "answer": 0,
    "explanation": "Adding a fixed effect to an unconditional growth model makes it a Conditional Growth Model.",
    "id": 358,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output - Interaction in GCM]\nReference is Diet1. What does `Time:Diet3` = 4.00 mean?",
    "options": [
      "Diet3 chicks are 4 grams heavier than Diet1 chicks at the start.",
      "Diet3 chicks grow at a rate 4 units *faster* per time unit...",
      "Diet3 chicks grow at a rate of 4 units per time unit total.",
      "Diet3 has no effect. (additional context) (addi"
    ],
    "answer": 1,
    "explanation": "The interaction term indicates the difference in slope relative to the reference group.",
    "id": 359,
    "codeSnippet": "Fixed effects:\nTime:Diet2    2.50   (p = 0.03)\nTime:Diet3    4.00   (p = 0.001)",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: You run a mixed model and get: `boundary (singular) fit: see ?isSingular`. What is a likely cause?",
    "options": [
      "The fixed effects are not significant.",
      "The random effects variance is estimated...",
      "You have too much data. (in statistics)",
      "The residuals are not normal. approach"
    ],
    "answer": 1,
    "explanation": "Singular fit usually indicates that the random effects variance is estimated to be near zero or perfectly correlated.",
    "id": 360,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: Which plot is best for checking the **homoscedasticity** assumption?",
    "options": [
      "Q-Q Plot.",
      "Residuals vs. Fitted Plot.",
      "Histogram of Residuals.",
      "Scatterplot of X vs Y."
    ],
    "answer": 1,
    "explanation": "Looking for a \"funnel\" or random cloud, not a pattern).",
    "id": 361,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: Which plot is best for checking the **normality of residuals** assumption?",
    "options": [
      "Q-Q Plot.",
      "Residuals vs. Fitted Plot.",
      "Cook's Distance Plot.",
      "Boxplot of predictors."
    ],
    "answer": 0,
    "explanation": "A Q-Q plot compares the residuals' distribution to a theoretical normal distribution.",
    "id": 362,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nObservation 3 has a hat value of 0.60 (much higher than others). What does this indicate?",
    "options": [
      "It is an outlier in the Y direction.",
      "It has high leverage (outlier in X space).",
      "It has high influence (Cook's D).",
      "It is perfectly normal."
    ],
    "answer": 1,
    "explanation": "Hat values measure leverage, which identifies outliers in the predictor space.",
    "id": 363,
    "codeSnippet": "hatvalues(model)\n1      2      3 ...\n0.05   0.02   0.60",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: To formally test if a specific influential point is changing your coefficients significantly, what metric would you look at?",
    "options": [
      "R-squared",
      "Cook's Distance",
      "AIC",
      "The intercept"
    ],
    "answer": 1,
    "explanation": "Cook's Distance measures the influence of a data point on the model coefficients.",
    "id": 364,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: In a polynomial regression `y ~ x + I(x^2)`, you decide to center `x` (i.e., `x_centered = x - mean(x)`). What effect does this typically have?",
    "options": [
      "It changes the shape of the curve.",
      "It changes the $R^2$ of the model.",
      "It reduces the correlation (multicollinearit...",
      "It makes the model non-linear. methodology"
    ],
    "answer": 2,
    "explanation": "Centering variables reduces structural multicollinearity between the linear and polynomial terms.",
    "id": 365,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nWhat does \"Satterthwaite's method\" refer to?",
    "options": [
      "A method for estimating degrees of...",
      "A method for calculating R-squared.",
      "A method for outlier detection.",
      "A type of plot. (in statistics)"
    ],
    "answer": 0,
    "explanation": "Satterthwaite's method is used to estimate effective degrees of freedom for t-tests in mixed models.",
    "id": 366,
    "codeSnippet": "Linear mixed model fit by REML\nt-tests use Satterthwaite's method",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: If you are analyzing repeated measures data (e.g., 3 time points per person) using `lm()` (standard regression), which assumption are you definitely violating?",
    "options": [
      "Linearity. methodology",
      "Independence of observat...",
      "Normality. methodology",
      "Homoscedasticity."
    ],
    "answer": 1,
    "explanation": "Standard regression assumes independence, which is violated by repeated measures on the same subjects.",
    "id": 367,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: What is the range of possible values for the Intraclass Correlation Coefficient (ICC)?",
    "options": [
      "-1 to 1",
      "0 to 1",
      "-infinity to +infinity",
      "0 to 100"
    ],
    "answer": 1,
    "explanation": "ICC ranges from 0 to 1, representing the proportion of variance explained by the grouping structure.",
    "id": 368,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: An ICC of 0 indicates:",
    "options": [
      "Perfect clustering (all variance is between groups).",
      "No clustering (all variance is within groups/...",
      "The model is broken. (in statistics)",
      "Strong negative correlation. methodology"
    ],
    "answer": 1,
    "explanation": "An ICC of 0 means there is no variance between groups; all variance is within groups.",
    "id": 369,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: You want to predict `Vocabulary` growth in children (ages 2 to 10). You expect growth to be fast at first and then slow down. Which polynomial term coefficient should be **negative** in your model?",
    "options": [
      "The Intercept methodology",
      "The Linear Time slope",
      "The Quadratic Time slope (`I(T...",
      "The Random Intercept"
    ],
    "answer": 2,
    "explanation": "A negative quadratic term creates a downward curvature, representing deceleration.",
    "id": 370,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nWhich model is better according to AIC?",
    "options": [
      "The Additive model (+)",
      "The Interaction model (\\*)"
    ],
    "answer": 1,
    "explanation": "Lower AIC is better).",
    "id": 371,
    "codeSnippet": "Formula: weight ~ Time + Diet\nAIC: 5500\nFormula: weight ~ Time * Diet\nAIC: 5400",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: When reporting a Growth Curve Analysis, what is crucial to include besides the p-values?",
    "options": [
      "The raw data for every participant.",
      "The type of polynomial used, the random...",
      "The name of the computer used.",
      "Only the R-squared. (in statistics)"
    ],
    "answer": 1,
    "explanation": "Reporting requirements include the model structure, random effects, and parameter estimates, not just significance.",
    "id": 372,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: In `ggplot2`, which geometric object is useful for adding the fitted regression line (including polynomial fits) to a plot?",
    "options": [
      "`geom_point()`",
      "`geom_smooth()`",
      "`geom_bar()`",
      "`geom_boxplot()`"
    ],
    "answer": 1,
    "explanation": "geom_smooth adds a smoothed conditional mean, often a regression line.",
    "id": 373,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output - Orthogonal Polynomials]\nCan you interpret the coefficient `50.0` as \"the increase in outcome for a 1-unit increase in Time\"?",
    "options": [
      "Yes. (in statistics)",
      "No, because orth..."
    ],
    "answer": 1,
    "explanation": "Orthogonal polynomials are transformed and uncorrelated, so coefficients don't represent simple unit changes in the raw variable.",
    "id": 374,
    "codeSnippet": "Coefficients:\n(Intercept)  10.0\npoly(Time,2)1 50.0\npoly(Time,2)2 10.0",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: Which function from the `performance` package can you use to check model performance metrics (like $R^2$, AIC, ICC) all at once?",
    "options": [
      "`summary()` methodology",
      "`model_performance()` or",
      "`plot()` (in statistics)",
      "`anova()` methodology"
    ],
    "answer": 1,
    "explanation": "The performance package provides tools like model_performance() to check multiple metrics.",
    "id": 375,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nIs the predictor significant?",
    "options": [
      "Yes, p = 0.008.",
      "No.",
      "The null model is better.",
      "AIC suggests the null model."
    ],
    "answer": 0,
    "explanation": "P-value < 0.05 indicates statistical significance.",
    "id": 376,
    "codeSnippet": "anova(m_null, m_full)\nModels:\nm_null: outcome ~ 1 + (1 | group)\nm_full: outcome ~ predictor + (1 | group)\nDf    AIC    BIC  logLik  Chisq Chi Df Pr(>Chisq)\nm_null  3 1050.0 1060.0 -522.0\nm_full  4 1045.0 1058.0 -518.5   7.0      1   0.008 **",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: What is a \"Random Slope\"?",
    "options": [
      "It allows the relationship between a predicto...",
      "It allows the mean of the outcome to vary across groups.",
      "It is the error term. (in statistics)",
      "It is a fixed constant. (in statistics)"
    ],
    "answer": 0,
    "explanation": "Random slopes allow the effect of a predictor to vary by group/subject.",
    "id": 377,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: In the equation $Y_{si} = b_{0s} + b_{1s}Time_i + e_{si}$, if $b_{1s} = b_1 + S_{1s}$, what does $S_{1s}$ represent?",
    "options": [
      "The fixed slope for the whole population.",
      "The random deviation of subject $s$'...",
      "The intercept. (in statistics)",
      "The residual error. methodology"
    ],
    "answer": 1,
    "explanation": "S_1s is the subject-specific random deviation from the population fixed slope.",
    "id": 378,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: If you are studying \"Teams\" nested in \"Organizations,\" how would you specify nested random intercepts in `lmer`?",
    "options": [
      "`(1 | Organization) + (1 | Team)` (if Team IDs are unique across organizations).",
      "`(1 | Organization/Team)` (if Team IDs are recycled, e.g., Team 1 in Org A and Team 1 in Org B).",
      "Both A and B can be correct depending on coding.",
      "All of the above."
    ],
    "answer": 3,
    "explanation": "Both specifications can work depending on whether IDs are unique or recycled, making 'All of the above' the safest answer.",
    "id": 379,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: What does `REML=FALSE` (Maximum Likelihood) allow you to do that `REML=TRUE` does not?",
    "options": [
      "Get accurate variance estimates.",
      "Compare models with different **fixe...",
      "Run the model faster. methodology",
      "Ignore assumptions. methodology"
    ],
    "answer": 1,
    "explanation": "ML (REML=FALSE) is required when comparing models with different fixed effects using LRT.",
    "id": 380,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nThere is a high correlation (-0.85) between the `Time` and `Time2` (quadratic) estimates. What does this suggest?",
    "options": [
      "The model is wrong. approach",
      "This is essential multicollinea...",
      "Time causes Time2. approach",
      "You should drop Time2."
    ],
    "answer": 1,
    "explanation": "High correlation between polynomial terms usually indicates essential multicollinearity; centering helps.",
    "id": 381,
    "codeSnippet": "Correlation of Fixed Effects:\n(Intr)  Time\nTime  -0.40\nTime2  0.10   -0.85",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: Why is it dangerous to interpret the main effect of `Time` in a model where the interaction `Time:Diet` is significant?",
    "options": [
      "Because the effect of Time depends on which Diet the...",
      "Because Time is not real. in data analysis",
      "Because the p-values are wrong. (in statistics)",
      "You should always interpret main effects regardless of interactions."
    ],
    "answer": 0,
    "explanation": "An interaction means the effect of one variable changes depending on the level of the other.",
    "id": 382,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: A researcher uses a 10th-order polynomial for a dataset with 20 points. What is the likely problem?",
    "options": [
      "Underfitting.",
      "Overfitting (modeling noise).",
      "Perfect fit (good thing).",
      "Linearity."
    ],
    "answer": 1,
    "explanation": "Using a high-degree polynomial on small data fits noise, leading to overfitting.",
    "id": 383,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: If the `t-value` for a fixed effect in `lmer` is 1.5, is it statistically significant at alpha=0.05?",
    "options": [
      "Yes.",
      "No (Needs to be \\> \\~1.96).",
      "Yes, because it's positive."
    ],
    "answer": 1,
    "explanation": "A t-value of 1.5 corresponds to a p-value > 0.05; significance usually requires |t| >= 1.96.",
    "id": 384,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: What does the \"Intercept\" represent in a model using orthogonal polynomials `poly(x, 2)`?",
    "options": [
      "The value of Y when x = 0.",
      "The grand mean of Y.",
      "It has no meaning.",
      "The slope."
    ],
    "answer": 1,
    "explanation": "With orthogonal polynomials, the intercept represents the grand mean of the response.",
    "id": 385,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nWhat can you conclude about the effect of Treatment?",
    "options": [
      "It is statistically significant.",
      "It is not statistically significant...",
      "The effect size is exactly 0.",
      "The effect is negative. methodology"
    ],
    "answer": 1,
    "explanation": "If the confidence interval includes zero, the effect is not statistically significant.",
    "id": 386,
    "codeSnippet": "Confidence Intervals (95%)\nVariable      2.5%    97.5%\nTreatment     -0.5     2.3",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: In the context of the ChickWeight data used in class, what was the dependent variable?",
    "options": [
      "Time",
      "Diet",
      "Weight",
      "Chick ID"
    ],
    "answer": 2,
    "explanation": "In the ChickWeight dataset, Weight is the outcome variable.",
    "id": 387,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: You want to check if a random slope for `Day` improves your model `m0`.\n`m0 <- lmer(y ~ Day + (1|Subj))`\n`m1 <- lmer(y ~ Day + (1 + Day|Subj))`\n`anova(m0, m1)` yields p = 0.60.\nWhat do you do?",
    "options": [
      "Keep the random slope (m1) because more complex is better.",
      "Stick with the simpler model (m0) because the random...",
      "Change the fixed effects. in data analysis"
    ],
    "answer": 1,
    "explanation": "If the more complex model (m1) is not significantly better (p > 0.05), prefer the simpler model (m0).",
    "id": 388,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: What does the function `coef(model)` return for a mixed model?",
    "options": [
      "Only the fixed effects.",
      "Only the variance components.",
      "The sum of fixed effects + random...",
      "The p-values. (in statistics)"
    ],
    "answer": 2,
    "explanation": "coef() returns the sum of fixed and random effects for each group.",
    "id": 389,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: What does the function `fixef(model)` return?",
    "options": [
      "The fixed effects estimates...",
      "The random effects.",
      "The residuals. methodology"
    ],
    "answer": 0,
    "explanation": "fixef() extracts only the fixed effects parameters.",
    "id": 390,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nIf you add random slopes and the RMSE drops to 25.0, does the model fit better or worse?",
    "options": [
      "Worse (higher error).",
      "Better (lower error)."
    ],
    "answer": 1,
    "explanation": "Lower RMSE indicates smaller prediction errors, hence a better fit.",
    "id": 391,
    "codeSnippet": "Data: sleepstudy\nFormula: Reaction ~ Days + (1 | Subject)\nRMSE: 30.0",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: In the \"Politeness\" data example from class, \"Attitude\" (polite vs informal) was a:",
    "options": [
      "Random Effect.",
      "Fixed Effect.",
      "Outcome variable.",
      "Covariate."
    ],
    "answer": 1,
    "explanation": "Attitude was a manipulated condition, thus a Fixed Effect.",
    "id": 392,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: In the \"Politeness\" data example, \"Scenario\" (different situations like asking for a favor) was modeled as:",
    "options": [
      "Fixed Effect.",
      "Random Intercept.",
      "Outcome.",
      "Not included."
    ],
    "answer": 1,
    "explanation": "Scenario was a random factor, specifically a Random Intercept.",
    "id": 393,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "tf",
    "question": "Question: True or False: You can typically use `lmer` to analyze data with only 1 observation per subject.",
    "options": [
      "True.",
      "False (You generally need multiple observations per group to estimate random effects/variance within group)."
    ],
    "answer": 1,
    "explanation": "Mixed models require multiple observations per group to separate within-group and between-group variance.",
    "id": 394,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: Which is a valid reason to use a **conditional** R-squared?",
    "options": [
      "To see how much variance the fixed effects explain alone.",
      "To see how much variance the *entire* model (includ...",
      "To calculate p-values. (additional cont"
    ],
    "answer": 1,
    "explanation": "Conditional R-squared measures variance explained by both fixed and random effects.",
    "id": 395,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question: If your residual plot shows a \"fan\" shape (spread increases as fitted values increase), which assumption is violated?",
    "options": [
      "Normality. methodology",
      "Homoscedasticity (Homog...",
      "Linearity. methodology",
      "Independence. approach"
    ],
    "answer": 1,
    "explanation": "A fan shape in residuals indicates heteroscedasticity, violating the homoscedasticity assumption.",
    "id": 396,
    "module": "Module 13: Course Wrap-up & Integration"
  },
  {
    "type": "mc",
    "question": "Question:** **[Mock R Output]\nBecause this uses orthogonal polynomials, what is the correlation between the estimates for `Poly(Time,2)1` (linear component) and `Poly(Time,2)2` (quadratic component)?",
    "options": [
      "High positive. approach",
      "High negative. approach",
      "Zero (by definition of...",
      "Unknown. (in statistics)"
    ],
    "answer": 2,
    "explanation": "Orthogonal polynomials are constructed to be uncorrelated with each other.",
    "id": 397,
    "codeSnippet": "(Intercept)   100\nPoly(Time,2)1  10\nPoly(Time,2)2  -5",
    "codeOutput": "Output hidden for quiz mode",
    "module": "Module 13: Course Wrap-up & Integration"
  }
]